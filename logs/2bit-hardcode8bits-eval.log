Starting ...
Ready.
Quantizing layer 1/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 6020.791     | -          | -         | 1.698 |
| self_attn.v_proj | 180.202      | -          | -         | 1.240 |
| self_attn.q_proj | 8014.107     | -          | -         | 1.221 |
| self_attn.o_proj | 4.741        | -          | -         | 1.478 |
| mlp.up_proj      | 4349.743     | -          | -         | 1.485 |
| mlp.gate_proj    | 4515.372     | -          | -         | 1.203 |
| mlp.down_proj    | 43.647       | -          | -         | 4.316 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 2/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 26186.391    | -          | -         | 1.581 |
| self_attn.v_proj | 1235.167     | -          | -         | 1.238 |
| self_attn.q_proj | 26588.799    | -          | -         | 1.258 |
| self_attn.o_proj | 124.909      | -          | -         | 1.512 |
| mlp.up_proj      | 18382.549    | -          | -         | 1.547 |
| mlp.gate_proj    | 20729.637    | -          | -         | 1.242 |
quantize to 8 bits
| mlp.down_proj    | 1.692        | -          | -         | 4.352 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 3/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 75664.141    | -          | -         | 1.593 |
| self_attn.v_proj | 18598.279    | -          | -         | 1.268 |
| self_attn.q_proj | 67822.812    | -          | -         | 1.285 |
| self_attn.o_proj | 283.664      | -          | -         | 1.500 |
| mlp.up_proj      | 48499.812    | -          | -         | 1.568 |
| mlp.gate_proj    | 55692.133    | -          | -         | 1.233 |
| mlp.down_proj    | 1114.486     | -          | -         | 4.347 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 4/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 240983.688   | -          | -         | 1.572 |
| self_attn.v_proj | 62681.531    | -          | -         | 1.249 |
| self_attn.q_proj | 222406.844   | -          | -         | 1.238 |
| self_attn.o_proj | 572.329      | -          | -         | 1.494 |
| mlp.up_proj      | 82089.125    | -          | -         | 1.543 |
| mlp.gate_proj    | 95715.945    | -          | -         | 1.199 |
| mlp.down_proj    | 2039.873     | -          | -         | 4.265 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 5/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 233861.438   | -          | -         | 1.542 |
| self_attn.v_proj | 63209.289    | -          | -         | 1.225 |
| self_attn.q_proj | 220805.781   | -          | -         | 1.203 |
| self_attn.o_proj | 800.373      | -          | -         | 1.455 |
| mlp.up_proj      | 118421.047   | -          | -         | 1.519 |
| mlp.gate_proj    | 145872.906   | -          | -         | 1.230 |
| mlp.down_proj    | 3797.893     | -          | -         | 4.323 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 6/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 283144.969   | -          | -         | 1.517 |
| self_attn.v_proj | 77354.297    | -          | -         | 1.190 |
| self_attn.q_proj | 257552.719   | -          | -         | 1.215 |
| self_attn.o_proj | 1524.488     | -          | -         | 1.462 |
| mlp.up_proj      | 140428.281   | -          | -         | 1.502 |
| mlp.gate_proj    | 175164.031   | -          | -         | 1.195 |
| mlp.down_proj    | 5175.518     | -          | -         | 4.271 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 7/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 380481.750   | -          | -         | 1.556 |
| self_attn.v_proj | 106453.797   | -          | -         | 1.184 |
| self_attn.q_proj | 366566.875   | -          | -         | 1.189 |
| self_attn.o_proj | 1532.620     | -          | -         | 1.451 |
| mlp.up_proj      | 167981.406   | -          | -         | 1.487 |
| mlp.gate_proj    | 218216.812   | -          | -         | 1.221 |
| mlp.down_proj    | 7028.546     | -          | -         | 4.301 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 8/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 399603.875   | -          | -         | 1.547 |
| self_attn.v_proj | 118476.922   | -          | -         | 1.198 |
| self_attn.q_proj | 394340.625   | -          | -         | 1.198 |
| self_attn.o_proj | 2107.328     | -          | -         | 1.506 |
| mlp.up_proj      | 195916.125   | -          | -         | 1.489 |
| mlp.gate_proj    | 252277.750   | -          | -         | 1.232 |
| mlp.down_proj    | 9271.266     | -          | -         | 4.325 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 9/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 398566.812   | -          | -         | 1.555 |
| self_attn.v_proj | 121515.375   | -          | -         | 1.237 |
| self_attn.q_proj | 391284.812   | -          | -         | 1.198 |
| self_attn.o_proj | 3516.063     | -          | -         | 1.472 |
| mlp.up_proj      | 212575.062   | -          | -         | 1.523 |
| mlp.gate_proj    | 258907.188   | -          | -         | 1.208 |
| mlp.down_proj    | 11213.764    | -          | -         | 4.288 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 10/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 444124.875   | -          | -         | 1.546 |
| self_attn.v_proj | 135580.781   | -          | -         | 1.224 |
| self_attn.q_proj | 417023       | -          | -         | 1.222 |
| self_attn.o_proj | 4364.503     | -          | -         | 1.514 |
| mlp.up_proj      | 232296.484   | -          | -         | 1.542 |
| mlp.gate_proj    | 273724.188   | -          | -         | 1.206 |
| mlp.down_proj    | 12740.084    | -          | -         | 4.430 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 11/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 457961.438   | -          | -         | 1.555 |
| self_attn.v_proj | 136064.797   | -          | -         | 1.217 |
| self_attn.q_proj | 423074.219   | -          | -         | 1.198 |
| self_attn.o_proj | 5939.165     | -          | -         | 1.457 |
| mlp.up_proj      | 249213.516   | -          | -         | 1.504 |
| mlp.gate_proj    | 285655.938   | -          | -         | 1.208 |
| mlp.down_proj    | 14593.199    | -          | -         | 4.311 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 12/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 471004.500   | -          | -         | 1.568 |
| self_attn.v_proj | 180109.750   | -          | -         | 1.228 |
| self_attn.q_proj | 467825.688   | -          | -         | 1.198 |
| self_attn.o_proj | 7002.995     | -          | -         | 1.452 |
| mlp.up_proj      | 265544.719   | -          | -         | 1.526 |
| mlp.gate_proj    | 297164.656   | -          | -         | 1.234 |
| mlp.down_proj    | 16451.938    | -          | -         | 4.292 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 13/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 516040.906   | -          | -         | 1.551 |
| self_attn.v_proj | 173676.688   | -          | -         | 1.229 |
| self_attn.q_proj | 479681.062   | -          | -         | 1.206 |
| self_attn.o_proj | 6738.145     | -          | -         | 1.495 |
| mlp.up_proj      | 282081.062   | -          | -         | 1.620 |
| mlp.gate_proj    | 305937.469   | -          | -         | 1.280 |
| mlp.down_proj    | 18850.506    | -          | -         | 4.402 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 14/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 501533.250   | -          | -         | 1.557 |
| self_attn.v_proj | 190320.484   | -          | -         | 1.263 |
| self_attn.q_proj | 481342.688   | -          | -         | 1.224 |
| self_attn.o_proj | 8082.010     | -          | -         | 1.475 |
| mlp.up_proj      | 310263.719   | -          | -         | 1.502 |
| mlp.gate_proj    | 327859.156   | -          | -         | 1.246 |
| mlp.down_proj    | 23502.578    | -          | -         | 4.311 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 15/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 535520.438   | -          | -         | 1.557 |
| self_attn.v_proj | 194732.375   | -          | -         | 1.220 |
| self_attn.q_proj | 505215.625   | -          | -         | 1.233 |
| self_attn.o_proj | 10761.293    | -          | -         | 1.516 |
| mlp.up_proj      | 338302.438   | -          | -         | 1.570 |
| mlp.gate_proj    | 355158.188   | -          | -         | 1.288 |
| mlp.down_proj    | 28612.725    | -          | -         | 4.346 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 16/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 516005.219   | -          | -         | 1.524 |
| self_attn.v_proj | 201479.453   | -          | -         | 1.206 |
| self_attn.q_proj | 482195.250   | -          | -         | 1.216 |
| self_attn.o_proj | 13269.152    | -          | -         | 1.487 |
| mlp.up_proj      | 374913.875   | -          | -         | 1.513 |
| mlp.gate_proj    | 393287.312   | -          | -         | 1.221 |
| mlp.down_proj    | 37699.352    | -          | -         | 4.403 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 17/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 541348.250   | -          | -         | 1.597 |
| self_attn.v_proj | 235841.688   | -          | -         | 1.276 |
| self_attn.q_proj | 512991.188   | -          | -         | 1.288 |
| self_attn.o_proj | 17615.273    | -          | -         | 1.469 |
| mlp.up_proj      | 423007.812   | -          | -         | 1.575 |
| mlp.gate_proj    | 450299.312   | -          | -         | 1.209 |
| mlp.down_proj    | 48566.230    | -          | -         | 4.393 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 18/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 540111.375   | -          | -         | 1.551 |
| self_attn.v_proj | 242501.578   | -          | -         | 1.197 |
| self_attn.q_proj | 518672.094   | -          | -         | 1.204 |
| self_attn.o_proj | 13851.959    | -          | -         | 1.482 |
| mlp.up_proj      | 487549.688   | -          | -         | 1.538 |
| mlp.gate_proj    | 533193.438   | -          | -         | 1.228 |
| mlp.down_proj    | 56911.094    | -          | -         | 4.286 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 19/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 593405.750   | -          | -         | 1.578 |
| self_attn.v_proj | 307133.125   | -          | -         | 1.196 |
| self_attn.q_proj | 575526       | -          | -         | 1.238 |
| self_attn.o_proj | 15437.964    | -          | -         | 1.467 |
| mlp.up_proj      | 543974.875   | -          | -         | 1.533 |
| mlp.gate_proj    | 608904.438   | -          | -         | 1.227 |
| mlp.down_proj    | 69691.234    | -          | -         | 4.254 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 20/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 575199.625   | -          | -         | 1.572 |
| self_attn.v_proj | 309608.250   | -          | -         | 1.197 |
| self_attn.q_proj | 557999.125   | -          | -         | 1.215 |
| self_attn.o_proj | 15711.459    | -          | -         | 1.485 |
| mlp.up_proj      | 585918.625   | -          | -         | 1.576 |
| mlp.gate_proj    | 660758.625   | -          | -         | 1.265 |
| mlp.down_proj    | 79515.508    | -          | -         | 4.440 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 21/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 593007.375   | -          | -         | 1.613 |
| self_attn.v_proj | 325397       | -          | -         | 1.230 |
| self_attn.q_proj | 577778.812   | -          | -         | 1.199 |
| self_attn.o_proj | 20483.213    | -          | -         | 1.487 |
| mlp.up_proj      | 613888.188   | -          | -         | 1.549 |
| mlp.gate_proj    | 700593.688   | -          | -         | 1.220 |
| mlp.down_proj    | 89695.508    | -          | -         | 4.253 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 22/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 608836.625   | -          | -         | 1.545 |
| self_attn.v_proj | 377434.375   | -          | -         | 1.202 |
| self_attn.q_proj | 601793.250   | -          | -         | 1.196 |
| self_attn.o_proj | 17016.924    | -          | -         | 1.457 |
| mlp.up_proj      | 656199.625   | -          | -         | 1.543 |
| mlp.gate_proj    | 761571.500   | -          | -         | 1.234 |
| mlp.down_proj    | 95908.953    | -          | -         | 4.261 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 23/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 661743.938   | -          | -         | 1.557 |
| self_attn.v_proj | 394413.344   | -          | -         | 1.187 |
| self_attn.q_proj | 650571.500   | -          | -         | 1.218 |
| self_attn.o_proj | 25239.957    | -          | -         | 1.486 |
| mlp.up_proj      | 687693.750   | -          | -         | 1.587 |
| mlp.gate_proj    | 808993       | -          | -         | 1.270 |
| mlp.down_proj    | 104602.922   | -          | -         | 4.367 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 24/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 714798.750   | -          | -         | 1.609 |
| self_attn.v_proj | 482423.281   | -          | -         | 1.267 |
| self_attn.q_proj | 710904.875   | -          | -         | 1.282 |
| self_attn.o_proj | 18588.809    | -          | -         | 1.501 |
| mlp.up_proj      | 741080.438   | -          | -         | 1.589 |
| mlp.gate_proj    | 862135.750   | -          | -         | 1.286 |
| mlp.down_proj    | 115374.625   | -          | -         | 4.379 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 25/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 660917.938   | -          | -         | 1.552 |
| self_attn.v_proj | 460830.938   | -          | -         | 1.211 |
| self_attn.q_proj | 655352.688   | -          | -         | 1.198 |
| self_attn.o_proj | 21766.324    | -          | -         | 1.445 |
| mlp.up_proj      | 778155.375   | -          | -         | 1.521 |
| mlp.gate_proj    | 904804.938   | -          | -         | 1.211 |
| mlp.down_proj    | 122178.047   | -          | -         | 4.274 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 26/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 757991.875   | -          | -         | 1.553 |
| self_attn.v_proj | 570081.750   | -          | -         | 1.213 |
| self_attn.q_proj | 756979.750   | -          | -         | 1.218 |
| self_attn.o_proj | 14830.039    | -          | -         | 1.444 |
| mlp.up_proj      | 835328.750   | -          | -         | 1.520 |
| mlp.gate_proj    | 966786.625   | -          | -         | 1.228 |
| mlp.down_proj    | 133846.125   | -          | -         | 4.253 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 27/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 729674.188   | -          | -         | 1.540 |
| self_attn.v_proj | 573457.250   | -          | -         | 1.202 |
| self_attn.q_proj | 723025.312   | -          | -         | 1.214 |
| self_attn.o_proj | 30010.238    | -          | -         | 1.446 |
| mlp.up_proj      | 898983.500   | -          | -         | 1.535 |
| mlp.gate_proj    | 1037716      | -          | -         | 1.218 |
| mlp.down_proj    | 151354.062   | -          | -         | 4.256 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 28/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 801591       | -          | -         | 1.546 |
| self_attn.v_proj | 596045.375   | -          | -         | 1.202 |
| self_attn.q_proj | 796496.250   | -          | -         | 1.205 |
| self_attn.o_proj | 26705.125    | -          | -         | 1.494 |
| mlp.up_proj      | 969601.125   | -          | -         | 1.585 |
| mlp.gate_proj    | 1111286.750  | -          | -         | 1.254 |
| mlp.down_proj    | 176192.625   | -          | -         | 4.424 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 29/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 802356.250   | -          | -         | 1.568 |
| self_attn.v_proj | 667865.062   | -          | -         | 1.203 |
| self_attn.q_proj | 793897.250   | -          | -         | 1.211 |
| self_attn.o_proj | 35117.398    | -          | -         | 1.503 |
| mlp.up_proj      | 1052756.750  | -          | -         | 1.582 |
| mlp.gate_proj    | 1172066.500  | -          | -         | 1.271 |
| mlp.down_proj    | 221060.781   | -          | -         | 4.364 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 30/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 718038       | -          | -         | 1.578 |
| self_attn.v_proj | 634988.500   | -          | -         | 1.219 |
| self_attn.q_proj | 719814.938   | -          | -         | 1.208 |
| self_attn.o_proj | 33652.945    | -          | -         | 1.467 |
| mlp.up_proj      | 1126110.500  | -          | -         | 1.583 |
| mlp.gate_proj    | 1238435.500  | -          | -         | 1.270 |
| mlp.down_proj    | 292555.250   | -          | -         | 4.335 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 31/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 785746.375   | -          | -         | 1.600 |
| self_attn.v_proj | 719841       | -          | -         | 1.228 |
| self_attn.q_proj | 775357.688   | -          | -         | 1.242 |
| self_attn.o_proj | 38502.113    | -          | -         | 1.531 |
| mlp.up_proj      | 1171602.125  | -          | -         | 1.553 |
| mlp.gate_proj    | 1304679.375  | -          | -         | 1.260 |
| mlp.down_proj    | 519353.375   | -          | -         | 4.373 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 32/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 576761.875   | -          | -         | 1.575 |
| self_attn.v_proj | 403838.219   | -          | -         | 1.249 |
| self_attn.q_proj | 542698.125   | -          | -         | 1.227 |
| self_attn.o_proj | 82274.195    | -          | -         | 1.511 |
| mlp.up_proj      | 979340.125   | -          | -         | 1.544 |
| mlp.gate_proj    | 1098561.250  | -          | -         | 1.265 |
| mlp.down_proj    | 1035715.188  | -          | -         | 4.417 |
+------------------+--------------+------------+-----------+-------+


752.5708951950073
wikitext2
PPL:  32.53498077392578
ptb
PPL:  377.5989685058594
c4
PPL:  30.04014015197754
