Starting ...
Ready.
Quantizing layer 1/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 1006.617     | -          | -         | 6.058 |
| self_attn.v_proj | 137.828      | -          | -         | 7.054 |
| self_attn.q_proj | 1052.833     | -          | -         | 5.283 |
| self_attn.o_proj | 0.008        | -          | -         | 9.201 |
| mlp.up_proj      | 140.958      | -          | -         | 8.043 |
| mlp.gate_proj    | 145.502      | -          | -         | 7.776 |
| mlp.down_proj    | 0.788        | -          | -         | 25.335 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  142336
dyn_bits:  162635


Quantizing layer 2/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 679.258      | -          | -         | 8.031 |
| self_attn.v_proj | 83.198       | -          | -         | 9.998 |
| self_attn.q_proj | 642.864      | -          | -         | 8.004 |
| self_attn.o_proj | 21.465       | -          | -         | 10.353 |
| mlp.up_proj      | 451.748      | -          | -         | 8.570 |
| mlp.gate_proj    | 508.929      | -          | -         | 8.068 |
| mlp.down_proj    | 22.151       | -          | -         | 25.645 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  284672
dyn_bits:  368833


Quantizing layer 3/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 127.735      | -          | -         | 9.504 |
| self_attn.v_proj | 579.466      | -          | -         | 8.038 |
| self_attn.q_proj | 114.475      | -          | -         | 9.112 |
| self_attn.o_proj | 23.383       | -          | -         | 10.505 |
| mlp.up_proj      | 121.946      | -          | -         | 10.353 |
| mlp.gate_proj    | 150.227      | -          | -         | 10.246 |
| mlp.down_proj    | 0.814        | -          | -         | 26.819 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  427008
dyn_bits:  616090


Quantizing layer 4/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 6206.880     | -          | -         | 8.328 |
| self_attn.v_proj | 1204.326     | -          | -         | 8.422 |
| self_attn.q_proj | 7066.217     | -          | -         | 7.738 |
| self_attn.o_proj | 0.589        | -          | -         | 10.023 |
| mlp.up_proj      | 260.371      | -          | -         | 10.612 |
| mlp.gate_proj    | 334.876      | -          | -         | 10.194 |
| mlp.down_proj    | 1.974        | -          | -         | 27.107 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  569344
dyn_bits:  851321


Quantizing layer 5/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 7566.705     | -          | -         | 8.059 |
| self_attn.v_proj | 2118.287     | -          | -         | 7.756 |
| self_attn.q_proj | 7186.656     | -          | -         | 7.688 |
| self_attn.o_proj | 0.907        | -          | -         | 10.151 |
| mlp.up_proj      | 3945.337     | -          | -         | 8.077 |
| mlp.gate_proj    | 4849.454     | -          | -         | 7.673 |
| mlp.down_proj    | 43.775       | -          | -         | 26.296 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  711680
dyn_bits:  1042905


Quantizing layer 6/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 9282.166     | -          | -         | 8.047 |
| self_attn.v_proj | 2612.909     | -          | -         | 7.785 |
| self_attn.q_proj | 8500.240     | -          | -         | 7.838 |
| self_attn.o_proj | 3.440        | -          | -         | 9.286 |
| mlp.up_proj      | 765.526      | -          | -         | 9.984 |
| mlp.gate_proj    | 6179.047     | -          | -         | 7.753 |
| mlp.down_proj    | 10.587       | -          | -         | 25.246 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  854016
dyn_bits:  1231210


Quantizing layer 7/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 10868.183    | -          | -         | 9.929 |
| self_attn.v_proj | 4044.061     | -          | -         | 10.045 |
| self_attn.q_proj | 10206.672    | -          | -         | 9.659 |
| self_attn.o_proj | 157.454      | -          | -         | 10.215 |
| mlp.up_proj      | 6056.168     | -          | -         | 7.948 |
| mlp.gate_proj    | 4756.224     | -          | -         | 8.577 |
| mlp.down_proj    | 12.553       | -          | -         | 25.648 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  996352
dyn_bits:  1468615


Quantizing layer 8/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 40849.242    | -          | -         | 8.122 |
| self_attn.v_proj | 4790.699     | -          | -         | 10.138 |
| self_attn.q_proj | 40065.250    | -          | -         | 8.015 |
| self_attn.o_proj | 50.179       | -          | -         | 10.101 |
| mlp.up_proj      | 6924.187     | -          | -         | 8.129 |
| mlp.gate_proj    | 8899.051     | -          | -         | 7.740 |
| mlp.down_proj    | 10.295       | -          | -         | 26.689 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  1138688
dyn_bits:  1684854


Quantizing layer 9/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 63794.668    | -          | -         | 6.895 |
| self_attn.v_proj | 5254.717     | -          | -         | 10.120 |
| self_attn.q_proj | 11307.338    | -          | -         | 9.876 |
| self_attn.o_proj | 9.473        | -          | -         | 8.976 |
| mlp.up_proj      | 4362.546     | -          | -         | 8.643 |
| mlp.gate_proj    | 5349.483     | -          | -         | 8.634 |
| mlp.down_proj    | 5.161        | -          | -         | 27.154 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  1281024
dyn_bits:  1916729


Quantizing layer 10/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 71385.766    | -          | -         | 6.480 |
| self_attn.v_proj | 5433.312     | -          | -         | 9.618 |
| self_attn.q_proj | 37219.676    | -          | -         | 7.871 |
| self_attn.o_proj | 13.503       | -          | -         | 9.608 |
| mlp.up_proj      | 6918.594     | -          | -         | 7.866 |
| mlp.gate_proj    | 6771.885     | -          | -         | 7.963 |
| mlp.down_proj    | 19.188       | -          | -         | 24.892 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  1423360
dyn_bits:  2130563


Quantizing layer 11/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 24087.125    | -          | -         | 8.845 |
| self_attn.v_proj | 5902.596     | -          | -         | 9.488 |
| self_attn.q_proj | 31216.281    | -          | -         | 8.126 |
| self_attn.o_proj | 132.732      | -          | -         | 9.792 |
| mlp.up_proj      | 9101.248     | -          | -         | 7.713 |
| mlp.gate_proj    | 10415.896    | -          | -         | 7.574 |
| mlp.down_proj    | 6.920        | -          | -         | 27.587 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  1565696
dyn_bits:  2366552


Quantizing layer 12/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 2736.892     | -          | -         | 10.033 |
| self_attn.v_proj | 718.606      | -          | -         | 9.707 |
| self_attn.q_proj | 2470.522     | -          | -         | 9.790 |
| self_attn.o_proj | 98.080       | -          | -         | 10.096 |
| mlp.up_proj      | 8579.925     | -          | -         | 8.020 |
| mlp.gate_proj    | 11327.049    | -          | -         | 7.466 |
| mlp.down_proj    | 3.523        | -          | -         | 28.000 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  1708032
dyn_bits:  2616021


Quantizing layer 13/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 6114.056     | -          | -         | 9.700 |
| self_attn.v_proj | 6510.724     | -          | -         | 7.685 |
| self_attn.q_proj | 17938.723    | -          | -         | 7.623 |
| self_attn.o_proj | 116.764      | -          | -         | 10.188 |
| mlp.up_proj      | 11032.152    | -          | -         | 7.703 |
| mlp.gate_proj    | 8489.583     | -          | -         | 7.830 |
| mlp.down_proj    | 28.051       | -          | -         | 25.283 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  1850368
dyn_bits:  2825201


Quantizing layer 14/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 3381.425     | -          | -         | 9.756 |
| self_attn.v_proj | 7362.651     | -          | -         | 7.361 |
| self_attn.q_proj | 12421.521    | -          | -         | 8.173 |
| self_attn.o_proj | 429.739      | -          | -         | 7.554 |
| mlp.up_proj      | 11943.770    | -          | -         | 7.610 |
| mlp.gate_proj    | 12608.543    | -          | -         | 7.344 |
| mlp.down_proj    | 23.655       | -          | -         | 25.968 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  1992704
dyn_bits:  3026455


Quantizing layer 15/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 20033.703    | -          | -         | 7.562 |
| self_attn.v_proj | 7353.708     | -          | -         | 7.306 |
| self_attn.q_proj | 172.095      | -          | -         | 9.558 |
| self_attn.o_proj | 30.199       | -          | -         | 8.778 |
| mlp.up_proj      | 13288.315    | -          | -         | 7.592 |
| mlp.gate_proj    | 13922.047    | -          | -         | 7.296 |
| mlp.down_proj    | 53.862       | -          | -         | 24.928 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  2135040
dyn_bits:  3223775


Quantizing layer 16/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 508.647      | -          | -         | 9.559 |
| self_attn.v_proj | 438.469      | -          | -         | 8.328 |
| self_attn.q_proj | 1026.912     | -          | -         | 8.384 |
| self_attn.o_proj | 31.551       | -          | -         | 8.882 |
| mlp.up_proj      | 7921.269     | -          | -         | 8.647 |
| mlp.gate_proj    | 15256.275    | -          | -         | 7.347 |
| mlp.down_proj    | 46.432       | -          | -         | 25.487 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  2277376
dyn_bits:  3447889


Quantizing layer 17/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 1140.953     | -          | -         | 8.694 |
| self_attn.v_proj | 209.068      | -          | -         | 8.935 |
| self_attn.q_proj | 1066.902     | -          | -         | 8.284 |
| self_attn.o_proj | 2934.995     | -          | -         | 7.383 |
| mlp.up_proj      | 5330.117     | -          | -         | 9.007 |
| mlp.gate_proj    | 17270.566    | -          | -         | 7.413 |
| mlp.down_proj    | 101.567      | -          | -         | 24.642 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  2419712
dyn_bits:  3660234


Quantizing layer 18/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 5212.922     | -          | -         | 9.395 |
| self_attn.v_proj | 7999.382     | -          | -         | 7.515 |
| self_attn.q_proj | 19552.477    | -          | -         | 7.300 |
| self_attn.o_proj | 24.446       | -          | -         | 9.286 |
| mlp.up_proj      | 18566.027    | -          | -         | 7.670 |
| mlp.gate_proj    | 20256.953    | -          | -         | 7.209 |
| mlp.down_proj    | 8.342        | -          | -         | 27.066 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  2562048
dyn_bits:  3873842


Quantizing layer 19/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 2440.828     | -          | -         | 9.693 |
| self_attn.v_proj | 895.549      | -          | -         | 9.558 |
| self_attn.q_proj | 2054.515     | -          | -         | 9.485 |
| self_attn.o_proj | 36.384       | -          | -         | 8.826 |
| mlp.up_proj      | 20677.533    | -          | -         | 7.639 |
| mlp.gate_proj    | 9733.678     | -          | -         | 8.487 |
| mlp.down_proj    | 103.403      | -          | -         | 25.296 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  2704384
dyn_bits:  4113952


Quantizing layer 20/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 9545.643     | -          | -         | 8.980 |
| self_attn.v_proj | 4749.279     | -          | -         | 8.629 |
| self_attn.q_proj | 20548.361    | -          | -         | 7.254 |
| self_attn.o_proj | 36.149       | -          | -         | 8.760 |
| mlp.up_proj      | 22267.871    | -          | -         | 7.608 |
| mlp.gate_proj    | 86.570       | -          | -         | 9.694 |
| mlp.down_proj    | 181.380      | -          | -         | 23.469 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  2846720
dyn_bits:  4322422


Quantizing layer 21/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 22128.514    | -          | -         | 7.756 |
| self_attn.v_proj | 5647.586     | -          | -         | 8.627 |
| self_attn.q_proj | 21290.387    | -          | -         | 7.448 |
| self_attn.o_proj | 795.484      | -          | -         | 7.690 |
| mlp.up_proj      | 19689.648    | -          | -         | 7.960 |
| mlp.gate_proj    | 16944.893    | -          | -         | 8.131 |
| mlp.down_proj    | 135.847      | -          | -         | 25.325 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  2989056
dyn_bits:  4514620


Quantizing layer 22/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 22928.199    | -          | -         | 7.678 |
| self_attn.v_proj | 14444.003    | -          | -         | 7.365 |
| self_attn.q_proj | 22282.066    | -          | -         | 7.421 |
| self_attn.o_proj | 21.633       | -          | -         | 9.621 |
| mlp.up_proj      | 85.674       | -          | -         | 10.124 |
| mlp.gate_proj    | 99.273       | -          | -         | 9.898 |
| mlp.down_proj    | 178.155      | -          | -         | 24.811 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  3131392
dyn_bits:  4731826


Quantizing layer 23/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 21231.119    | -          | -         | 7.968 |
| self_attn.v_proj | 5955.425     | -          | -         | 8.679 |
| self_attn.q_proj | 20533.189    | -          | -         | 7.599 |
| self_attn.o_proj | 459.742      | -          | -         | 8.943 |
| mlp.up_proj      | 2759.128     | -          | -         | 9.496 |
| mlp.gate_proj    | 3342.928     | -          | -         | 9.414 |
| mlp.down_proj    | 131.534      | -          | -         | 25.776 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  3273728
dyn_bits:  4963980


Quantizing layer 24/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 12853.697    | -          | -         | 8.836 |
| self_attn.v_proj | 8352.360     | -          | -         | 8.659 |
| self_attn.q_proj | 12531.364    | -          | -         | 8.600 |
| self_attn.o_proj | 44.100       | -          | -         | 9.174 |
| mlp.up_proj      | 97.672       | -          | -         | 9.943 |
| mlp.gate_proj    | 113.432      | -          | -         | 9.619 |
| mlp.down_proj    | 51.554       | -          | -         | 26.773 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  3416064
dyn_bits:  5217802


Quantizing layer 25/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 8224.764     | -          | -         | 9.128 |
| self_attn.v_proj | 17744.121    | -          | -         | 7.331 |
| self_attn.q_proj | 24578.068    | -          | -         | 7.383 |
| self_attn.o_proj | 49.880       | -          | -         | 8.884 |
| mlp.up_proj      | 30290.299    | -          | -         | 7.529 |
| mlp.gate_proj    | 35149.250    | -          | -         | 7.246 |
| mlp.down_proj    | 101.200      | -          | -         | 26.311 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  3558400
dyn_bits:  5422916


Quantizing layer 26/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 29358.074    | -          | -         | 7.647 |
| self_attn.v_proj | 22379.494    | -          | -         | 7.244 |
| self_attn.q_proj | 29201.912    | -          | -         | 7.309 |
| self_attn.o_proj | 6.176        | -          | -         | 9.791 |
| mlp.up_proj      | 112.881      | -          | -         | 9.833 |
| mlp.gate_proj    | 130.408      | -          | -         | 9.608 |
| mlp.down_proj    | 163.103      | -          | -         | 25.700 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  3700736
dyn_bits:  5651766


Quantizing layer 27/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 27712.301    | -          | -         | 7.546 |
| self_attn.v_proj | 942.433      | -          | -         | 9.476 |
| self_attn.q_proj | 4229.198     | -          | -         | 9.377 |
| self_attn.o_proj | 3125.741     | -          | -         | 9.741 |
| mlp.up_proj      | 120.961      | -          | -         | 9.958 |
| mlp.gate_proj    | 139.517      | -          | -         | 9.620 |
| mlp.down_proj    | 1940.028     | -          | -         | 25.863 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  3843072
dyn_bits:  5911719


Quantizing layer 28/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 30924.340    | -          | -         | 7.598 |
| self_attn.v_proj | 15705.884    | -          | -         | 7.900 |
| self_attn.q_proj | 9094.356     | -          | -         | 9.071 |
| self_attn.o_proj | 41.236       | -          | -         | 9.765 |
| mlp.up_proj      | 129.668      | -          | -         | 10.177 |
| mlp.gate_proj    | 148.484      | -          | -         | 9.813 |
| mlp.down_proj    | 404.108      | -          | -         | 24.325 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  3985408
dyn_bits:  6139371


Quantizing layer 29/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 20979.623    | -          | -         | 8.457 |
| self_attn.v_proj | 17297.863    | -          | -         | 8.129 |
| self_attn.q_proj | 1179.668     | -          | -         | 8.951 |
| self_attn.o_proj | 46.904       | -          | -         | 9.876 |
| mlp.up_proj      | 20534.977    | -          | -         | 8.836 |
| mlp.gate_proj    | 36244.688    | -          | -         | 7.863 |
| mlp.down_proj    | 190.300      | -          | -         | 27.127 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  4127744
dyn_bits:  6366719


Quantizing layer 30/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 1499.530     | -          | -         | 9.044 |
| self_attn.v_proj | 695.289      | -          | -         | 9.266 |
| self_attn.q_proj | 784.228      | -          | -         | 9.224 |
| self_attn.o_proj | 1508.931     | -          | -         | 7.705 |
| mlp.up_proj      | 41670.441    | -          | -         | 7.766 |
| mlp.gate_proj    | 45837.629    | -          | -         | 7.429 |
| mlp.down_proj    | 7422.922     | -          | -         | 23.506 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  4270080
dyn_bits:  6559041


Quantizing layer 31/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 2152.297     | -          | -         | 10.050 |
| self_attn.v_proj | 1446.731     | -          | -         | 9.702 |
| self_attn.q_proj | 2022.464     | -          | -         | 9.668 |
| self_attn.o_proj | 73.016       | -          | -         | 9.602 |
| mlp.up_proj      | 41948.914    | -          | -         | 7.660 |
| mlp.gate_proj    | 46729.117    | -          | -         | 7.463 |
| mlp.down_proj    | 54028.371    | -          | -         | 27.520 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  4412416
dyn_bits:  6805049


Quantizing layer 32/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 9082.824     | -          | -         | 9.073 |
| self_attn.v_proj | 1176.184     | -          | -         | 9.602 |
| self_attn.q_proj | 2229.102     | -          | -         | 9.504 |
| self_attn.o_proj | 9573.365     | -          | -         | 10.089 |
| mlp.up_proj      | 3946.664     | -          | -         | 9.890 |
| mlp.gate_proj    | 4391.300     | -          | -         | 9.358 |
| mlp.down_proj    | 14609.867    | -          | -         | 26.546 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  4554752
dyn_bits:  7070689


2833.670807361603
save quantized tensors.
Saving ...
Done.
