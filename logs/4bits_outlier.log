Starting ...
Ready.
Quantizing layer 1/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 153.619      | -          | -         | 1.976 |
| self_attn.v_proj | 6.761        | -          | -         | 1.527 |
| self_attn.q_proj | 165.998      | -          | -         | 1.533 |
| self_attn.o_proj | 0.129        | -          | -         | 1.802 |
| mlp.up_proj      | 140.814      | -          | -         | 1.838 |
| mlp.gate_proj    | 145.344      | -          | -         | 1.554 |
| mlp.down_proj    | 1.209        | -          | -         | 5.125 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 2/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 681.480      | -          | -         | 1.925 |
| self_attn.v_proj | 41.239       | -          | -         | 1.543 |
| self_attn.q_proj | 652.518      | -          | -         | 1.593 |
| self_attn.o_proj | 4.304        | -          | -         | 1.840 |
| mlp.up_proj      | 573.014      | -          | -         | 1.865 |
| mlp.gate_proj    | 641.499      | -          | -         | 1.537 |
| mlp.down_proj    | 367.990      | -          | -         | 5.175 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 3/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 2424.437     | -          | -         | 1.925 |
| self_attn.v_proj | 629.588      | -          | -         | 1.543 |
| self_attn.q_proj | 2180.782     | -          | -         | 1.539 |
| self_attn.o_proj | 9.874        | -          | -         | 1.776 |
| mlp.up_proj      | 1555.366     | -          | -         | 1.863 |
| mlp.gate_proj    | 1781.307     | -          | -         | 1.566 |
| mlp.down_proj    | 33.254       | -          | -         | 5.157 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 4/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 7714.736     | -          | -         | 1.876 |
| self_attn.v_proj | 2061.824     | -          | -         | 1.536 |
| self_attn.q_proj | 7103.329     | -          | -         | 1.588 |
| self_attn.o_proj | 18.372       | -          | -         | 1.774 |
| mlp.up_proj      | 2925.237     | -          | -         | 1.863 |
| mlp.gate_proj    | 3400.582     | -          | -         | 1.561 |
| mlp.down_proj    | 70.840       | -          | -         | 5.183 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 5/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 7598.322     | -          | -         | 1.915 |
| self_attn.v_proj | 2128.300     | -          | -         | 1.543 |
| self_attn.q_proj | 7217.669     | -          | -         | 1.523 |
| self_attn.o_proj | 34.282       | -          | -         | 1.804 |
| mlp.up_proj      | 3967.520     | -          | -         | 1.855 |
| mlp.gate_proj    | 4877.101     | -          | -         | 1.601 |
| mlp.down_proj    | 130.144      | -          | -         | 5.202 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 6/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 9328.315     | -          | -         | 1.860 |
| self_attn.v_proj | 2623.995     | -          | -         | 1.539 |
| self_attn.q_proj | 8535.406     | -          | -         | 1.538 |
| self_attn.o_proj | 60.627       | -          | -         | 1.804 |
| mlp.up_proj      | 5006.095     | -          | -         | 1.908 |
| mlp.gate_proj    | 6221.376     | -          | -         | 1.598 |
| mlp.down_proj    | 196.705      | -          | -         | 5.157 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 7/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 13161.073    | -          | -         | 1.907 |
| self_attn.v_proj | 3736.304     | -          | -         | 1.568 |
| self_attn.q_proj | 12639.818    | -          | -         | 1.594 |
| self_attn.o_proj | 76.855       | -          | -         | 1.810 |
| mlp.up_proj      | 6109.814     | -          | -         | 1.841 |
| mlp.gate_proj    | 7916.202     | -          | -         | 1.559 |
| mlp.down_proj    | 281.529      | -          | -         | 5.196 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 8/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 14011.978    | -          | -         | 1.936 |
| self_attn.v_proj | 4190.678     | -          | -         | 1.558 |
| self_attn.q_proj | 13806.407    | -          | -         | 1.534 |
| self_attn.o_proj | 108.401      | -          | -         | 1.816 |
| mlp.up_proj      | 7132.964     | -          | -         | 1.887 |
| mlp.gate_proj    | 9163.083     | -          | -         | 1.590 |
| mlp.down_proj    | 374.298      | -          | -         | 5.238 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 9/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 14052.265    | -          | -         | 1.910 |
| self_attn.v_proj | 4326.086     | -          | -         | 1.567 |
| self_attn.q_proj | 13800.258    | -          | -         | 1.605 |
| self_attn.o_proj | 165.114      | -          | -         | 1.783 |
| mlp.up_proj      | 7807.049     | -          | -         | 1.939 |
| mlp.gate_proj    | 9489.176     | -          | -         | 1.605 |
| mlp.down_proj    | 463.549      | -          | -         | 5.236 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 10/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 15592.949    | -          | -         | 1.916 |
| self_attn.v_proj | 4799.227     | -          | -         | 1.640 |
| self_attn.q_proj | 14661.232    | -          | -         | 1.556 |
| self_attn.o_proj | 244.424      | -          | -         | 1.848 |
| mlp.up_proj      | 8595.918     | -          | -         | 1.841 |
| mlp.gate_proj    | 10106.045    | -          | -         | 1.559 |
| mlp.down_proj    | 547.212      | -          | -         | 5.220 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 11/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 16557.945    | -          | -         | 1.884 |
| self_attn.v_proj | 4939.198     | -          | -         | 1.550 |
| self_attn.q_proj | 15370.641    | -          | -         | 1.558 |
| self_attn.o_proj | 324.414      | -          | -         | 1.805 |
| mlp.up_proj      | 9235.578     | -          | -         | 1.907 |
| mlp.gate_proj    | 10572.698    | -          | -         | 1.562 |
| mlp.down_proj    | 632.849      | -          | -         | 5.185 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 12/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 17334.971    | -          | -         | 1.902 |
| self_attn.v_proj | 6651.105     | -          | -         | 1.569 |
| self_attn.q_proj | 17266.277    | -          | -         | 1.538 |
| self_attn.o_proj | 333.684      | -          | -         | 1.807 |
| mlp.up_proj      | 10259.198    | -          | -         | 1.848 |
| mlp.gate_proj    | 11466.324    | -          | -         | 1.547 |
| mlp.down_proj    | 725.628      | -          | -         | 5.227 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 13/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 19530.031    | -          | -         | 1.902 |
| self_attn.v_proj | 6590.870     | -          | -         | 1.557 |
| self_attn.q_proj | 18203.496    | -          | -         | 1.550 |
| self_attn.o_proj | 380.313      | -          | -         | 1.790 |
| mlp.up_proj      | 11211.950    | -          | -         | 1.852 |
| mlp.gate_proj    | 12152.469    | -          | -         | 1.569 |
| mlp.down_proj    | 849.460      | -          | -         | 5.178 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 14/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 19524.027    | -          | -         | 1.892 |
| self_attn.v_proj | 7444.606     | -          | -         | 1.544 |
| self_attn.q_proj | 18683.223    | -          | -         | 1.577 |
| self_attn.o_proj | 427.068      | -          | -         | 1.781 |
| mlp.up_proj      | 12087.479    | -          | -         | 1.873 |
| mlp.gate_proj    | 12761        | -          | -         | 1.572 |
| mlp.down_proj    | 1064.018     | -          | -         | 5.224 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 15/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 20220.023    | -          | -         | 1.900 |
| self_attn.v_proj | 7400.340     | -          | -         | 1.554 |
| self_attn.q_proj | 19143.336    | -          | -         | 1.522 |
| self_attn.o_proj | 535.103      | -          | -         | 1.828 |
| mlp.up_proj      | 13344.801    | -          | -         | 1.869 |
| mlp.gate_proj    | 13983.137    | -          | -         | 1.561 |
| mlp.down_proj    | 1265.044     | -          | -         | 5.189 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 16/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 19671.039    | -          | -         | 1.876 |
| self_attn.v_proj | 7774.307     | -          | -         | 1.535 |
| self_attn.q_proj | 18152.697    | -          | -         | 1.532 |
| self_attn.o_proj | 598.501      | -          | -         | 1.834 |
| mlp.up_proj      | 14565.295    | -          | -         | 1.866 |
| mlp.gate_proj    | 15270.144    | -          | -         | 1.568 |
| mlp.down_proj    | 1584.784     | -          | -         | 5.195 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 17/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 20198.918    | -          | -         | 1.891 |
| self_attn.v_proj | 8936.598     | -          | -         | 1.557 |
| self_attn.q_proj | 18877.955    | -          | -         | 1.543 |
| self_attn.o_proj | 803.508      | -          | -         | 1.785 |
| mlp.up_proj      | 16236.195    | -          | -         | 1.861 |
| mlp.gate_proj    | 17250.275    | -          | -         | 1.544 |
| mlp.down_proj    | 2097.696     | -          | -         | 5.233 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 18/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 20669.004    | -          | -         | 1.913 |
| self_attn.v_proj | 9382.350     | -          | -         | 1.564 |
| self_attn.q_proj | 19535.066    | -          | -         | 1.553 |
| self_attn.o_proj | 597.955      | -          | -         | 1.861 |
| mlp.up_proj      | 18498.014    | -          | -         | 1.871 |
| mlp.gate_proj    | 20174.203    | -          | -         | 1.583 |
| mlp.down_proj    | 2383.412     | -          | -         | 5.255 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 19/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 22311.381    | -          | -         | 1.910 |
| self_attn.v_proj | 11690.607    | -          | -         | 1.586 |
| self_attn.q_proj | 21222.973    | -          | -         | 1.622 |
| self_attn.o_proj | 658.303      | -          | -         | 1.834 |
| mlp.up_proj      | 20607.098    | -          | -         | 1.899 |
| mlp.gate_proj    | 23023.389    | -          | -         | 1.532 |
| mlp.down_proj    | 2833.690     | -          | -         | 5.232 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 20/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 21485.309    | -          | -         | 1.913 |
| self_attn.v_proj | 11738.456    | -          | -         | 1.583 |
| self_attn.q_proj | 20500.553    | -          | -         | 1.541 |
| self_attn.o_proj | 636.137      | -          | -         | 1.864 |
| mlp.up_proj      | 22166.055    | -          | -         | 1.950 |
| mlp.gate_proj    | 24964.750    | -          | -         | 1.603 |
| mlp.down_proj    | 3189.433     | -          | -         | 5.389 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 21/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 22045.379    | -          | -         | 1.901 |
| self_attn.v_proj | 12303.934    | -          | -         | 1.581 |
| self_attn.q_proj | 21215.457    | -          | -         | 1.578 |
| self_attn.o_proj | 794.685      | -          | -         | 1.841 |
| mlp.up_proj      | 23214.719    | -          | -         | 1.912 |
| mlp.gate_proj    | 26439.584    | -          | -         | 1.587 |
| mlp.down_proj    | 3752.281     | -          | -         | 5.216 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 22/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 22879.066    | -          | -         | 1.885 |
| self_attn.v_proj | 14399.068    | -          | -         | 1.586 |
| self_attn.q_proj | 22211.990    | -          | -         | 1.550 |
| self_attn.o_proj | 699.283      | -          | -         | 1.816 |
| mlp.up_proj      | 24741.289    | -          | -         | 1.874 |
| mlp.gate_proj    | 28663.066    | -          | -         | 1.576 |
| mlp.down_proj    | 3894.070     | -          | -         | 5.274 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 23/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 24623.629    | -          | -         | 1.924 |
| self_attn.v_proj | 14927.986    | -          | -         | 1.537 |
| self_attn.q_proj | 23894.148    | -          | -         | 1.565 |
| self_attn.o_proj | 884.753      | -          | -         | 1.828 |
| mlp.up_proj      | 26075.852    | -          | -         | 1.864 |
| mlp.gate_proj    | 30604.305    | -          | -         | 1.579 |
| mlp.down_proj    | 4440.376     | -          | -         | 5.224 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 24/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 26830.842    | -          | -         | 1.894 |
| self_attn.v_proj | 18393.178    | -          | -         | 1.558 |
| self_attn.q_proj | 26376.727    | -          | -         | 1.597 |
| self_attn.o_proj | 931.778      | -          | -         | 1.829 |
| mlp.up_proj      | 28280.605    | -          | -         | 1.904 |
| mlp.gate_proj    | 32854.109    | -          | -         | 1.574 |
| mlp.down_proj    | 4792.638     | -          | -         | 5.262 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 25/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 24954.650    | -          | -         | 1.953 |
| self_attn.v_proj | 17728.428    | -          | -         | 1.546 |
| self_attn.q_proj | 24585.754    | -          | -         | 1.534 |
| self_attn.o_proj | 966.378      | -          | -         | 1.851 |
| mlp.up_proj      | 30059.617    | -          | -         | 1.860 |
| mlp.gate_proj    | 34882.070    | -          | -         | 1.570 |
| mlp.down_proj    | 5138.504     | -          | -         | 5.283 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 26/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 29167.141    | -          | -         | 1.910 |
| self_attn.v_proj | 22227.576    | -          | -         | 1.567 |
| self_attn.q_proj | 28976.539    | -          | -         | 1.579 |
| self_attn.o_proj | 778.309      | -          | -         | 1.809 |
| mlp.up_proj      | 32452.061    | -          | -         | 1.920 |
| mlp.gate_proj    | 37508.461    | -          | -         | 1.574 |
| mlp.down_proj    | 5562.330     | -          | -         | 5.234 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 27/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 27552.648    | -          | -         | 1.934 |
| self_attn.v_proj | 22035.738    | -          | -         | 1.571 |
| self_attn.q_proj | 27109.967    | -          | -         | 1.541 |
| self_attn.o_proj | 1289.271     | -          | -         | 1.825 |
| mlp.up_proj      | 34610.320    | -          | -         | 1.854 |
| mlp.gate_proj    | 39921.746    | -          | -         | 1.570 |
| mlp.down_proj    | 6202.247     | -          | -         | 5.263 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 28/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 30535.859    | -          | -         | 1.921 |
| self_attn.v_proj | 22966.193    | -          | -         | 1.535 |
| self_attn.q_proj | 29944.756    | -          | -         | 1.554 |
| self_attn.o_proj | 1272.832     | -          | -         | 1.814 |
| mlp.up_proj      | 37085.629    | -          | -         | 1.873 |
| mlp.gate_proj    | 42480.961    | -          | -         | 1.604 |
| mlp.down_proj    | 7014.334     | -          | -         | 5.212 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 29/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 29952.027    | -          | -         | 1.895 |
| self_attn.v_proj | 25245.883    | -          | -         | 1.579 |
| self_attn.q_proj | 29237.961    | -          | -         | 1.636 |
| self_attn.o_proj | 1635.120     | -          | -         | 1.812 |
| mlp.up_proj      | 39482.648    | -          | -         | 1.849 |
| mlp.gate_proj    | 43950.891    | -          | -         | 1.536 |
| mlp.down_proj    | 8263.957     | -          | -         | 5.276 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 30/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 26216.154    | -          | -         | 1.992 |
| self_attn.v_proj | 23580.078    | -          | -         | 1.581 |
| self_attn.q_proj | 25882.646    | -          | -         | 1.576 |
| self_attn.o_proj | 1521.714     | -          | -         | 1.869 |
| mlp.up_proj      | 41231.289    | -          | -         | 1.884 |
| mlp.gate_proj    | 45333.625    | -          | -         | 1.607 |
| mlp.down_proj    | 9790.031     | -          | -         | 5.262 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 31/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 28176.248    | -          | -         | 1.897 |
| self_attn.v_proj | 26109.170    | -          | -         | 1.527 |
| self_attn.q_proj | 27473.055    | -          | -         | 1.605 |
| self_attn.o_proj | 1856.119     | -          | -         | 1.839 |
| mlp.up_proj      | 41459.758    | -          | -         | 1.925 |
| mlp.gate_proj    | 46174.430    | -          | -         | 1.613 |
| mlp.down_proj    | 14231.689    | -          | -         | 5.257 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 32/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 19825.584    | -          | -         | 1.923 |
| self_attn.v_proj | 14153.359    | -          | -         | 1.612 |
| self_attn.q_proj | 18484.750    | -          | -         | 1.627 |
| self_attn.o_proj | 1934.782     | -          | -         | 1.830 |
| mlp.up_proj      | 34390.418    | -          | -         | 1.873 |
| mlp.gate_proj    | 38568.625    | -          | -         | 1.592 |
| mlp.down_proj    | 25905.820    | -          | -         | 5.515 |
+------------------+--------------+------------+-----------+-------+


846.7268512248993
save quantized tensors.
Saving ...
Done.
