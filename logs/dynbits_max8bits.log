Starting ...
Ready.
Quantizing layer 1/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 173.219      | -          | -         | 7.088 |
| self_attn.v_proj | 3.491        | -          | -         | 6.713 |
| self_attn.q_proj | 198.041      | -          | -         | 6.567 |
| self_attn.o_proj | 0.006        | -          | -         | 6.819 |
| mlp.up_proj      | 0.740        | -          | -         | 6.972 |
| mlp.gate_proj    | 0.823        | -          | -         | 6.790 |
| mlp.down_proj    | 0.010        | -          | -         | 19.354 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 2/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 377.523      | -          | -         | 7.243 |
| self_attn.v_proj | 4.795        | -          | -         | 6.915 |
| self_attn.q_proj | 365.089      | -          | -         | 6.888 |
| self_attn.o_proj | 1.131        | -          | -         | 7.217 |
| mlp.up_proj      | 12.458       | -          | -         | 7.238 |
| mlp.gate_proj    | 15.959       | -          | -         | 6.823 |
| mlp.down_proj    | 1.747        | -          | -         | 19.810 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 3/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 20.902       | -          | -         | 7.119 |
| self_attn.v_proj | 3.667        | -          | -         | 6.835 |
| self_attn.q_proj | 17.421       | -          | -         | 6.910 |
| self_attn.o_proj | 1.200        | -          | -         | 7.095 |
| mlp.up_proj      | 33.248       | -          | -         | 7.232 |
| mlp.gate_proj    | 40.524       | -          | -         | 6.966 |
| mlp.down_proj    | 0.203        | -          | -         | 19.687 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 4/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 59.435       | -          | -         | 7.316 |
| self_attn.v_proj | 11.897       | -          | -         | 6.878 |
| self_attn.q_proj | 53.479       | -          | -         | 6.868 |
| self_attn.o_proj | 0.251        | -          | -         | 7.106 |
| mlp.up_proj      | 70.408       | -          | -         | 6.996 |
| mlp.gate_proj    | 90.152       | -          | -         | 6.656 |
| mlp.down_proj    | 0.421        | -          | -         | 18.991 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 5/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 71.485       | -          | -         | 7.015 |
| self_attn.v_proj | 13.529       | -          | -         | 6.609 |
| self_attn.q_proj | 60.292       | -          | -         | 6.642 |
| self_attn.o_proj | 0.318        | -          | -         | 6.999 |
| mlp.up_proj      | 114.490      | -          | -         | 7.003 |
| mlp.gate_proj    | 158.476      | -          | -         | 6.697 |
| mlp.down_proj    | 1.088        | -          | -         | 18.634 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 6/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 85.470       | -          | -         | 7.028 |
| self_attn.v_proj | 16.388       | -          | -         | 6.559 |
| self_attn.q_proj | 68.582       | -          | -         | 6.605 |
| self_attn.o_proj | 1.597        | -          | -         | 6.739 |
| mlp.up_proj      | 142.046      | -          | -         | 6.874 |
| mlp.gate_proj    | 199.836      | -          | -         | 6.640 |
| mlp.down_proj    | 0.708        | -          | -         | 18.526 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 7/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 1402.272     | -          | -         | 6.764 |
| self_attn.v_proj | 237.782      | -          | -         | 6.512 |
| self_attn.q_proj | 1273.880     | -          | -         | 6.460 |
| self_attn.o_proj | 0.714        | -          | -         | 7.009 |
| mlp.up_proj      | 191.208      | -          | -         | 6.793 |
| mlp.gate_proj    | 282.842      | -          | -         | 6.538 |
| mlp.down_proj    | 1.959        | -          | -         | 18.680 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 8/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 1606.467     | -          | -         | 6.885 |
| self_attn.v_proj | 297.463      | -          | -         | 6.510 |
| self_attn.q_proj | 1436.658     | -          | -         | 6.494 |
| self_attn.o_proj | 1.272        | -          | -         | 6.798 |
| mlp.up_proj      | 255.676      | -          | -         | 6.810 |
| mlp.gate_proj    | 376.812      | -          | -         | 6.407 |
| mlp.down_proj    | 1.371        | -          | -         | 18.846 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 9/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 1838.826     | -          | -         | 6.964 |
| self_attn.v_proj | 343.526      | -          | -         | 6.682 |
| self_attn.q_proj | 1630.107     | -          | -         | 6.705 |
| self_attn.o_proj | 2.054        | -          | -         | 6.980 |
| mlp.up_proj      | 53.193       | -          | -         | 7.024 |
| mlp.gate_proj    | 67.661       | -          | -         | 6.562 |
| mlp.down_proj    | 1.658        | -          | -         | 19.013 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 10/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 1950.253     | -          | -         | 6.860 |
| self_attn.v_proj | 370.808      | -          | -         | 6.508 |
| self_attn.q_proj | 1779.620     | -          | -         | 6.538 |
| self_attn.o_proj | 2.627        | -          | -         | 6.898 |
| mlp.up_proj      | 47.081       | -          | -         | 6.973 |
| mlp.gate_proj    | 58.603       | -          | -         | 6.671 |
| mlp.down_proj    | 3.538        | -          | -         | 18.840 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 11/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 2204.281     | -          | -         | 6.871 |
| self_attn.v_proj | 457.958      | -          | -         | 6.474 |
| self_attn.q_proj | 1794.276     | -          | -         | 6.442 |
| self_attn.o_proj | 5.000        | -          | -         | 6.809 |
| mlp.up_proj      | 63.371       | -          | -         | 6.771 |
| mlp.gate_proj    | 76.610       | -          | -         | 6.518 |
| mlp.down_proj    | 3.232        | -          | -         | 18.612 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 12/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 175.529      | -          | -         | 6.943 |
| self_attn.v_proj | 53.601       | -          | -         | 6.554 |
| self_attn.q_proj | 167.880      | -          | -         | 6.472 |
| self_attn.o_proj | 24.665       | -          | -         | 6.894 |
| mlp.up_proj      | 56.191       | -          | -         | 7.062 |
| mlp.gate_proj    | 67.010       | -          | -         | 6.668 |
| mlp.down_proj    | 4.560        | -          | -         | 18.883 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 13/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 192.076      | -          | -         | 6.845 |
| self_attn.v_proj | 53.913       | -          | -         | 6.565 |
| self_attn.q_proj | 170.447      | -          | -         | 6.561 |
| self_attn.o_proj | 29.077       | -          | -         | 6.884 |
| mlp.up_proj      | 61.043       | -          | -         | 6.907 |
| mlp.gate_proj    | 88.581       | -          | -         | 6.685 |
| mlp.down_proj    | 4.444        | -          | -         | 18.931 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 14/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 181.055      | -          | -         | 6.967 |
| self_attn.v_proj | 54.087       | -          | -         | 6.686 |
| self_attn.q_proj | 154.798      | -          | -         | 6.672 |
| self_attn.o_proj | 2.953        | -          | -         | 6.868 |
| mlp.up_proj      | 66.787       | -          | -         | 6.918 |
| mlp.gate_proj    | 112.276      | -          | -         | 6.640 |
| mlp.down_proj    | 5.922        | -          | -         | 18.756 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 15/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 201.999      | -          | -         | 6.731 |
| self_attn.v_proj | 55.860       | -          | -         | 6.450 |
| self_attn.q_proj | 168.852      | -          | -         | 6.498 |
| self_attn.o_proj | 3.615        | -          | -         | 6.721 |
| mlp.up_proj      | 91.819       | -          | -         | 6.698 |
| mlp.gate_proj    | 81.325       | -          | -         | 6.447 |
| mlp.down_proj    | 7.289        | -          | -         | 18.307 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 16/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 195.014      | -          | -         | 7.001 |
| self_attn.v_proj | 58.778       | -          | -         | 6.470 |
| self_attn.q_proj | 170.799      | -          | -         | 6.365 |
| self_attn.o_proj | 4.916        | -          | -         | 6.735 |
| mlp.up_proj      | 602.381      | -          | -         | 6.934 |
| mlp.gate_proj    | 726.655      | -          | -         | 6.471 |
| mlp.down_proj    | 9.170        | -          | -         | 18.536 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 17/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 230.217      | -          | -         | 6.757 |
| self_attn.v_proj | 75.896       | -          | -         | 6.417 |
| self_attn.q_proj | 188.042      | -          | -         | 6.564 |
| self_attn.o_proj | 40.230       | -          | -         | 6.805 |
| mlp.up_proj      | 1005.937     | -          | -         | 6.722 |
| mlp.gate_proj    | 1176.891     | -          | -         | 6.380 |
| mlp.down_proj    | 12.717       | -          | -         | 18.054 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 18/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 187.923      | -          | -         | 6.842 |
| self_attn.v_proj | 64.887       | -          | -         | 6.510 |
| self_attn.q_proj | 150.787      | -          | -         | 6.564 |
| self_attn.o_proj | 4.181        | -          | -         | 6.586 |
| mlp.up_proj      | 654.030      | -          | -         | 6.602 |
| mlp.gate_proj    | 809.550      | -          | -         | 6.407 |
| mlp.down_proj    | 13.967       | -          | -         | 18.410 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 19/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 224.870      | -          | -         | 6.768 |
| self_attn.v_proj | 77.634       | -          | -         | 6.413 |
| self_attn.q_proj | 191.896      | -          | -         | 6.484 |
| self_attn.o_proj | 6.046        | -          | -         | 6.753 |
| mlp.up_proj      | 706.339      | -          | -         | 6.832 |
| mlp.gate_proj    | 888.568      | -          | -         | 6.450 |
| mlp.down_proj    | 22.242       | -          | -         | 18.409 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 20/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 198.095      | -          | -         | 6.824 |
| self_attn.v_proj | 76.467       | -          | -         | 6.572 |
| self_attn.q_proj | 160.886      | -          | -         | 6.473 |
| self_attn.o_proj | 7.764        | -          | -         | 6.689 |
| mlp.up_proj      | 143.878      | -          | -         | 6.867 |
| mlp.gate_proj    | 277.479      | -          | -         | 6.440 |
| mlp.down_proj    | 20.377       | -          | -         | 18.469 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 21/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 201.032      | -          | -         | 6.808 |
| self_attn.v_proj | 76.726       | -          | -         | 6.524 |
| self_attn.q_proj | 204.829      | -          | -         | 6.421 |
| self_attn.o_proj | 51.158       | -          | -         | 6.751 |
| mlp.up_proj      | 689.835      | -          | -         | 6.715 |
| mlp.gate_proj    | 1577.434     | -          | -         | 6.299 |
| mlp.down_proj    | 24.428       | -          | -         | 18.531 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 22/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 234.591      | -          | -         | 6.814 |
| self_attn.v_proj | 87.392       | -          | -         | 6.358 |
| self_attn.q_proj | 200.594      | -          | -         | 6.403 |
| self_attn.o_proj | 5.311        | -          | -         | 6.734 |
| mlp.up_proj      | 734.687      | -          | -         | 6.630 |
| mlp.gate_proj    | 920.798      | -          | -         | 6.556 |
| mlp.down_proj    | 24.531       | -          | -         | 18.497 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 23/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 212.668      | -          | -         | 6.872 |
| self_attn.v_proj | 91.343       | -          | -         | 6.358 |
| self_attn.q_proj | 183.741      | -          | -         | 6.533 |
| self_attn.o_proj | 7.854        | -          | -         | 6.841 |
| mlp.up_proj      | 241.887      | -          | -         | 6.738 |
| mlp.gate_proj    | 290.053      | -          | -         | 6.402 |
| mlp.down_proj    | 27.726       | -          | -         | 18.554 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 24/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 205.967      | -          | -         | 6.803 |
| self_attn.v_proj | 106.312      | -          | -         | 6.585 |
| self_attn.q_proj | 186.955      | -          | -         | 6.333 |
| self_attn.o_proj | 10.169       | -          | -         | 6.748 |
| mlp.up_proj      | 825.824      | -          | -         | 6.664 |
| mlp.gate_proj    | 1013.967     | -          | -         | 6.464 |
| mlp.down_proj    | 31.376       | -          | -         | 18.392 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 25/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 261.705      | -          | -         | 6.787 |
| self_attn.v_proj | 106.799      | -          | -         | 6.523 |
| self_attn.q_proj | 265.545      | -          | -         | 6.704 |
| self_attn.o_proj | 9.605        | -          | -         | 6.953 |
| mlp.up_proj      | 148.241      | -          | -         | 7.175 |
| mlp.gate_proj    | 175.701      | -          | -         | 6.776 |
| mlp.down_proj    | 34.423       | -          | -         | 19.025 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 26/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 217.744      | -          | -         | 7.039 |
| self_attn.v_proj | 125.612      | -          | -         | 6.672 |
| self_attn.q_proj | 236.170      | -          | -         | 6.684 |
| self_attn.o_proj | 6.237        | -          | -         | 6.950 |
| mlp.up_proj      | 953.841      | -          | -         | 7.006 |
| mlp.gate_proj    | 1175.459     | -          | -         | 6.701 |
| mlp.down_proj    | 39.517       | -          | -         | 19.016 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 27/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 232.113      | -          | -         | 6.964 |
| self_attn.v_proj | 128.224      | -          | -         | 6.698 |
| self_attn.q_proj | 258.465      | -          | -         | 6.647 |
| self_attn.o_proj | 141.322      | -          | -         | 6.893 |
| mlp.up_proj      | 171.363      | -          | -         | 6.884 |
| mlp.gate_proj    | 201.626      | -          | -         | 6.500 |
| mlp.down_proj    | 53.039       | -          | -         | 18.470 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 28/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 300.457      | -          | -         | 6.781 |
| self_attn.v_proj | 189.193      | -          | -         | 6.617 |
| self_attn.q_proj | 286.804      | -          | -         | 6.570 |
| self_attn.o_proj | 10.994       | -          | -         | 6.611 |
| mlp.up_proj      | 185.117      | -          | -         | 6.820 |
| mlp.gate_proj    | 216.398      | -          | -         | 6.434 |
| mlp.down_proj    | 70.918       | -          | -         | 18.584 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 29/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 258.028      | -          | -         | 6.759 |
| self_attn.v_proj | 136.792      | -          | -         | 6.455 |
| self_attn.q_proj | 200.741      | -          | -         | 6.524 |
| self_attn.o_proj | 15.122       | -          | -         | 6.732 |
| mlp.up_proj      | 199.427      | -          | -         | 6.852 |
| mlp.gate_proj    | 226.873      | -          | -         | 6.526 |
| mlp.down_proj    | 86.551       | -          | -         | 18.664 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 30/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 204.801      | -          | -         | 6.910 |
| self_attn.v_proj | 127.186      | -          | -         | 6.522 |
| self_attn.q_proj | 184.976      | -          | -         | 6.329 |
| self_attn.o_proj | 221.837      | -          | -         | 6.628 |
| mlp.up_proj      | 1327.518     | -          | -         | 6.827 |
| mlp.gate_proj    | 1558.922     | -          | -         | 6.365 |
| mlp.down_proj    | 118.607      | -          | -         | 18.470 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 31/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 189.941      | -          | -         | 6.888 |
| self_attn.v_proj | 134.573      | -          | -         | 6.774 |
| self_attn.q_proj | 184.527      | -          | -         | 6.697 |
| self_attn.o_proj | 16.966       | -          | -         | 6.932 |
| mlp.up_proj      | 4985.145     | -          | -         | 6.560 |
| mlp.gate_proj    | 5658.607     | -          | -         | 6.297 |
| mlp.down_proj    | 3979.449     | -          | -         | 18.850 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 32/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 163.421      | -          | -         | 6.854 |
| self_attn.v_proj | 77.025       | -          | -         | 6.609 |
| self_attn.q_proj | 166.048      | -          | -         | 6.531 |
| self_attn.o_proj | 441.934      | -          | -         | 6.856 |
| mlp.up_proj      | 183.495      | -          | -         | 6.879 |
| mlp.gate_proj    | 205.767      | -          | -         | 6.552 |
| mlp.down_proj    | 9206.562     | -          | -         | 18.518 |
+------------------+--------------+------------+-----------+-------+


2232.1670796871185