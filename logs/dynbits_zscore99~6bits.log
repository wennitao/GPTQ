Starting ...
Ready.
Quantizing layer 1/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 1189.587     | -          | -         | 4.463 |
| self_attn.v_proj | 150.762      | -          | -         | 5.319 |
| self_attn.q_proj | 1349.450     | -          | -         | 4.080 |
| self_attn.o_proj | 0.009        | -          | -         | 7.085 |
| mlp.up_proj      | 21.508       | -          | -         | 7.749 |
| mlp.gate_proj    | 23.657       | -          | -         | 7.506 |
| mlp.down_proj    | 0.681        | -          | -         | 20.042 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  142336
dyn_bits:  195539


Quantizing layer 2/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 789.451      | -          | -         | 5.952 |
| self_attn.v_proj | 95.591       | -          | -         | 7.635 |
| self_attn.q_proj | 768.830      | -          | -         | 5.880 |
| self_attn.o_proj | 23.715       | -          | -         | 8.045 |
| mlp.up_proj      | 591.998      | -          | -         | 6.280 |
| mlp.gate_proj    | 663.786      | -          | -         | 5.929 |
| mlp.down_proj    | 25.712       | -          | -         | 19.310 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  284672
dyn_bits:  394386


Quantizing layer 3/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 65.347       | -          | -         | 7.642 |
| self_attn.v_proj | 234.234      | -          | -         | 6.766 |
| self_attn.q_proj | 57.238       | -          | -         | 7.155 |
| self_attn.o_proj | 25.822       | -          | -         | 7.841 |
| mlp.up_proj      | 132.372      | -          | -         | 7.857 |
| mlp.gate_proj    | 162.164      | -          | -         | 7.562 |
| mlp.down_proj    | 1.226        | -          | -         | 20.502 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  427008
dyn_bits:  653688


Quantizing layer 4/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 2940.481     | -          | -         | 7.304 |
| self_attn.v_proj | 678.599      | -          | -         | 7.040 |
| self_attn.q_proj | 2659.492     | -          | -         | 6.971 |
| self_attn.o_proj | 1.106        | -          | -         | 6.997 |
| mlp.up_proj      | 283.425      | -          | -         | 8.014 |
| mlp.gate_proj    | 366.549      | -          | -         | 7.497 |
| mlp.down_proj    | 1.994        | -          | -         | 20.391 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  569344
dyn_bits:  906558


Quantizing layer 5/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 5220.438     | -          | -         | 6.473 |
| self_attn.v_proj | 2198.521     | -          | -         | 5.589 |
| self_attn.q_proj | 7694.778     | -          | -         | 5.730 |
| self_attn.o_proj | 0.897        | -          | -         | 7.493 |
| mlp.up_proj      | 4099.248     | -          | -         | 6.026 |
| mlp.gate_proj    | 954.844      | -          | -         | 7.096 |
| mlp.down_proj    | 79.636       | -          | -         | 18.979 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  711680
dyn_bits:  1106606


Quantizing layer 6/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 9771.930     | -          | -         | 6.091 |
| self_attn.v_proj | 2727.022     | -          | -         | 5.783 |
| self_attn.q_proj | 8998.272     | -          | -         | 5.773 |
| self_attn.o_proj | 3.885        | -          | -         | 6.962 |
| mlp.up_proj      | 5182.071     | -          | -         | 6.145 |
| mlp.gate_proj    | 6435.911     | -          | -         | 5.860 |
| mlp.down_proj    | 7.035        | -          | -         | 20.361 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  854016
dyn_bits:  1291920


Quantizing layer 7/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 11820.342    | -          | -         | 7.742 |
| self_attn.v_proj | 4613.615     | -          | -         | 7.639 |
| self_attn.q_proj | 10955.845    | -          | -         | 7.414 |
| self_attn.o_proj | 4.705        | -          | -         | 7.065 |
| mlp.up_proj      | 6264.290     | -          | -         | 6.138 |
| mlp.gate_proj    | 1342.908     | -          | -         | 7.376 |
| mlp.down_proj    | 12.165       | -          | -         | 19.983 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  996352
dyn_bits:  1530345


Quantizing layer 8/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 67570.391    | -          | -         | 5.259 |
| self_attn.v_proj | 5717.935     | -          | -         | 7.686 |
| self_attn.q_proj | 66822.141    | -          | -         | 4.927 |
| self_attn.o_proj | 172.482      | -          | -         | 7.660 |
| mlp.up_proj      | 7321.953     | -          | -         | 6.085 |
| mlp.gate_proj    | 1827.139     | -          | -         | 7.102 |
| mlp.down_proj    | 9.908        | -          | -         | 20.341 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  1138688
dyn_bits:  1745755


Quantizing layer 9/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 60686.789    | -          | -         | 5.455 |
| self_attn.v_proj | 6105.076     | -          | -         | 7.379 |
| self_attn.q_proj | 65988.031    | -          | -         | 4.834 |
| self_attn.o_proj | 9.810        | -          | -         | 6.768 |
| mlp.up_proj      | 5847.858     | -          | -         | 6.326 |
| mlp.gate_proj    | 7135.732     | -          | -         | 6.063 |
| mlp.down_proj    | 12.355       | -          | -         | 20.337 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  1281024
dyn_bits:  1951371


Quantizing layer 10/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 73908.344    | -          | -         | 5.093 |
| self_attn.v_proj | 6256.272     | -          | -         | 7.430 |
| self_attn.q_proj | 69361.953    | -          | -         | 4.850 |
| self_attn.o_proj | 6.199        | -          | -         | 7.338 |
| mlp.up_proj      | 8720.424     | -          | -         | 5.937 |
| mlp.gate_proj    | 6895.465     | -          | -         | 6.154 |
| mlp.down_proj    | 7.325        | -          | -         | 20.686 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  1423360
dyn_bits:  2162911


Quantizing layer 11/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 70417.047    | -          | -         | 5.303 |
| self_attn.v_proj | 7420.799     | -          | -         | 7.410 |
| self_attn.q_proj | 40797.961    | -          | -         | 5.888 |
| self_attn.o_proj | 349.183      | -          | -         | 5.863 |
| mlp.up_proj      | 3852.456     | -          | -         | 6.930 |
| mlp.gate_proj    | 4469.506     | -          | -         | 6.645 |
| mlp.down_proj    | 3.137        | -          | -         | 21.008 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  1565696
dyn_bits:  2386652


Quantizing layer 12/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 17455.701    | -          | -         | 6.211 |
| self_attn.v_proj | 4108.106     | -          | -         | 6.593 |
| self_attn.q_proj | 10857.467    | -          | -         | 6.574 |
| self_attn.o_proj | 108.021      | -          | -         | 7.996 |
| mlp.up_proj      | 10336.238    | -          | -         | 6.271 |
| mlp.gate_proj    | 11544.728    | -          | -         | 5.897 |
| mlp.down_proj    | 78.086       | -          | -         | 21.677 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  1708032
dyn_bits:  2599994


Quantizing layer 13/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 6930.086     | -          | -         | 7.367 |
| self_attn.v_proj | 2142.909     | -          | -         | 6.959 |
| self_attn.q_proj | 6190.012     | -          | -         | 6.972 |
| self_attn.o_proj | 209.580      | -          | -         | 7.414 |
| mlp.up_proj      | 5051.280     | -          | -         | 7.180 |
| mlp.gate_proj    | 4846.511     | -          | -         | 6.852 |
| mlp.down_proj    | 7.138        | -          | -         | 21.783 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  1850368
dyn_bits:  2849267


Quantizing layer 14/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 19864.238    | -          | -         | 6.213 |
| self_attn.v_proj | 7620.292     | -          | -         | 5.903 |
| self_attn.q_proj | 12890.172    | -          | -         | 6.339 |
| self_attn.o_proj | 354.790      | -          | -         | 6.991 |
| mlp.up_proj      | 12277.072    | -          | -         | 5.994 |
| mlp.gate_proj    | 12457.898    | -          | -         | 5.653 |
| mlp.down_proj    | 41.902       | -          | -         | 19.630 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  1992704
dyn_bits:  3038004


Quantizing layer 15/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 765.880      | -          | -         | 7.253 |
| self_attn.v_proj | 7676.753     | -          | -         | 5.651 |
| self_attn.q_proj | 19814.906    | -          | -         | 5.717 |
| self_attn.o_proj | 9.854        | -          | -         | 7.510 |
| mlp.up_proj      | 8779.199     | -          | -         | 6.429 |
| mlp.gate_proj    | 9290.117     | -          | -         | 6.203 |
| mlp.down_proj    | 56.966       | -          | -         | 19.571 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  2135040
dyn_bits:  3247600


Quantizing layer 16/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 625.291      | -          | -         | 7.240 |
| self_attn.v_proj | 158.632      | -          | -         | 7.057 |
| self_attn.q_proj | 1071.854     | -          | -         | 6.463 |
| self_attn.o_proj | 10.379       | -          | -         | 7.553 |
| mlp.up_proj      | 15064.821    | -          | -         | 5.880 |
| mlp.gate_proj    | 3643.969     | -          | -         | 6.987 |
| mlp.down_proj    | 95.429       | -          | -         | 18.665 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  2277376
dyn_bits:  3474260


Quantizing layer 17/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 1190.787     | -          | -         | 6.789 |
| self_attn.v_proj | 138.813      | -          | -         | 7.297 |
| self_attn.q_proj | 1122.717     | -          | -         | 6.706 |
| self_attn.o_proj | 165.479      | -          | -         | 7.711 |
| mlp.up_proj      | 6012.154     | -          | -         | 7.119 |
| mlp.gate_proj    | 17852.033    | -          | -         | 5.773 |
| mlp.down_proj    | 66.528       | -          | -         | 20.422 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  2419712
dyn_bits:  3709788


Quantizing layer 18/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 11438.243    | -          | -         | 6.975 |
| self_attn.v_proj | 7008.673     | -          | -         | 6.129 |
| self_attn.q_proj | 5252.301     | -          | -         | 7.056 |
| self_attn.o_proj | 4.294        | -          | -         | 7.750 |
| mlp.up_proj      | 19200.951    | -          | -         | 5.974 |
| mlp.gate_proj    | 7056.738     | -          | -         | 6.844 |
| mlp.down_proj    | 8.685        | -          | -         | 21.394 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  2562048
dyn_bits:  3947474


Quantizing layer 19/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 4559.033     | -          | -         | 7.789 |
| self_attn.v_proj | 8683.490     | -          | -         | 7.319 |
| self_attn.q_proj | 22343.801    | -          | -         | 5.921 |
| self_attn.o_proj | 9.945        | -          | -         | 7.759 |
| mlp.up_proj      | 21345.355    | -          | -         | 6.083 |
| mlp.gate_proj    | 16103.507    | -          | -         | 6.412 |
| mlp.down_proj    | 100.480      | -          | -         | 20.172 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  2704384
dyn_bits:  4172601


Quantizing layer 20/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 7049.092     | -          | -         | 7.207 |
| self_attn.v_proj | 12207.128    | -          | -         | 5.616 |
| self_attn.q_proj | 21616.504    | -          | -         | 5.623 |
| self_attn.o_proj | 27.285       | -          | -         | 7.214 |
| mlp.up_proj      | 19448.031    | -          | -         | 6.165 |
| mlp.gate_proj    | 21969.635    | -          | -         | 5.938 |
| mlp.down_proj    | 52.086       | -          | -         | 21.257 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  2846720
dyn_bits:  4385481


Quantizing layer 21/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 5365.903     | -          | -         | 7.716 |
| self_attn.v_proj | 10284.102    | -          | -         | 7.139 |
| self_attn.q_proj | 22157.309    | -          | -         | 5.635 |
| self_attn.o_proj | 437.449      | -          | -         | 7.196 |
| mlp.up_proj      | 18496.801    | -          | -         | 6.572 |
| mlp.gate_proj    | 8237.150     | -          | -         | 7.172 |
| mlp.down_proj    | 24.287       | -          | -         | 22.086 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  2989056
dyn_bits:  4622185


Quantizing layer 22/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 4117.191     | -          | -         | 8.004 |
| self_attn.v_proj | 1846.568     | -          | -         | 7.648 |
| self_attn.q_proj | 3500.821     | -          | -         | 7.665 |
| self_attn.o_proj | 30.001       | -          | -         | 7.669 |
| mlp.up_proj      | 88.331       | -          | -         | 7.941 |
| mlp.gate_proj    | 102.264      | -          | -         | 7.673 |
| mlp.down_proj    | 110.766      | -          | -         | 20.809 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  3131392
dyn_bits:  4889699


Quantizing layer 23/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 25734.338    | -          | -         | 6.152 |
| self_attn.v_proj | 10455.970    | -          | -         | 6.348 |
| self_attn.q_proj | 25089.582    | -          | -         | 5.707 |
| self_attn.o_proj | 468.506      | -          | -         | 7.724 |
| mlp.up_proj      | 8810.298     | -          | -         | 7.437 |
| mlp.gate_proj    | 18185.279    | -          | -         | 6.641 |
| mlp.down_proj    | 260.676      | -          | -         | 19.383 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  3273728
dyn_bits:  5089870


Quantizing layer 24/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 10340.488    | -          | -         | 7.494 |
| self_attn.v_proj | 3295.197     | -          | -         | 7.391 |
| self_attn.q_proj | 11846.313    | -          | -         | 6.930 |
| self_attn.o_proj | 848.434      | -          | -         | 6.947 |
| mlp.up_proj      | 100.944      | -          | -         | 7.935 |
| mlp.gate_proj    | 117.208      | -          | -         | 7.768 |
| mlp.down_proj    | 134.454      | -          | -         | 21.228 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  3416064
dyn_bits:  5342499


Quantizing layer 25/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 3966.676     | -          | -         | 7.909 |
| self_attn.v_proj | 1818.862     | -          | -         | 7.530 |
| self_attn.q_proj | 4020.130     | -          | -         | 7.528 |
| self_attn.o_proj | 55.726       | -          | -         | 7.041 |
| mlp.up_proj      | 31049.648    | -          | -         | 6.098 |
| mlp.gate_proj    | 36004.836    | -          | -         | 5.853 |
| mlp.down_proj    | 163.301      | -          | -         | 20.466 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  3558400
dyn_bits:  5574305


Quantizing layer 26/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 8718.090     | -          | -         | 7.394 |
| self_attn.v_proj | 22956.820    | -          | -         | 5.772 |
| self_attn.q_proj | 30558.945    | -          | -         | 5.703 |
| self_attn.o_proj | 6.246        | -          | -         | 7.852 |
| mlp.up_proj      | 115.651      | -          | -         | 7.894 |
| mlp.gate_proj    | 133.729      | -          | -         | 7.589 |
| mlp.down_proj    | 324.609      | -          | -         | 19.121 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  3700736
dyn_bits:  5800375


Quantizing layer 27/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 14365.849    | -          | -         | 7.048 |
| self_attn.v_proj | 22778.209    | -          | -         | 5.805 |
| self_attn.q_proj | 7614.480     | -          | -         | 7.234 |
| self_attn.o_proj | 3247.935     | -          | -         | 7.848 |
| mlp.up_proj      | 123.050      | -          | -         | 8.018 |
| mlp.gate_proj    | 141.909      | -          | -         | 7.647 |
| mlp.down_proj    | 1319.703     | -          | -         | 21.253 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  3843072
dyn_bits:  6054325


Quantizing layer 28/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 13297.438    | -          | -         | 7.214 |
| self_attn.v_proj | 23677.363    | -          | -         | 5.838 |
| self_attn.q_proj | 25057.516    | -          | -         | 6.117 |
| self_attn.o_proj | 74.164       | -          | -         | 7.052 |
| mlp.up_proj      | 131.968      | -          | -         | 7.935 |
| mlp.gate_proj    | 151.086      | -          | -         | 7.587 |
| mlp.down_proj    | 111.785      | -          | -         | 21.343 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  3985408
dyn_bits:  6292781


Quantizing layer 29/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 31128.434    | -          | -         | 6.115 |
| self_attn.v_proj | 26061.143    | -          | -         | 5.764 |
| self_attn.q_proj | 18961.418    | -          | -         | 6.478 |
| self_attn.o_proj | 95.312       | -          | -         | 7.086 |
| mlp.up_proj      | 40624.188    | -          | -         | 6.167 |
| mlp.gate_proj    | 45203.828    | -          | -         | 5.821 |
| mlp.down_proj    | 125.549      | -          | -         | 21.291 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  4127744
dyn_bits:  6492507


Quantizing layer 30/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 1021.436     | -          | -         | 7.426 |
| self_attn.v_proj | 193.233      | -          | -         | 7.547 |
| self_attn.q_proj | 1605.999     | -          | -         | 6.639 |
| self_attn.o_proj | 1533.448     | -          | -         | 6.140 |
| mlp.up_proj      | 42396.438    | -          | -         | 6.124 |
| mlp.gate_proj    | 46602.949    | -          | -         | 5.848 |
| mlp.down_proj    | 336.480      | -          | -         | 20.913 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  4270080
dyn_bits:  6707685


Quantizing layer 31/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 8830.230     | -          | -         | 7.305 |
| self_attn.v_proj | 26878.584    | -          | -         | 5.804 |
| self_attn.q_proj | 8452.240     | -          | -         | 7.040 |
| self_attn.o_proj | 40.835       | -          | -         | 7.768 |
| mlp.up_proj      | 42648.031    | -          | -         | 6.122 |
| mlp.gate_proj    | 47539.133    | -          | -         | 5.797 |
| mlp.down_proj    | 45276.910    | -          | -         | 19.139 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  4412416
dyn_bits:  6915311


Quantizing layer 32/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 20886.094    | -          | -         | 6.050 |
| self_attn.v_proj | 14733.439    | -          | -         | 5.773 |
| self_attn.q_proj | 19808.781    | -          | -         | 5.802 |
| self_attn.o_proj | 10531.698    | -          | -         | 7.949 |
| mlp.up_proj      | 7048.901     | -          | -         | 7.610 |
| mlp.gate_proj    | 7866.863     | -          | -         | 7.082 |
| mlp.down_proj    | 10054.152    | -          | -         | 20.890 |
+------------------+--------------+------------+-----------+-------+
orig_bits:  4554752
dyn_bits:  7139929


2292.2123260498047
save quantized tensors.
Saving ...
Done.
