Starting ...
Ready.
Quantizing layer 1/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 182.349      | -          | -         | 1.714 |
| self_attn.v_proj | 7.743        | -          | -         | 1.245 |
| self_attn.q_proj | 206.937      | -          | -         | 1.257 |
| self_attn.o_proj | 0.145        | -          | -         | 1.513 |
| mlp.up_proj      | 146.115      | -          | -         | 1.516 |
| mlp.gate_proj    | 150.995      | -          | -         | 1.254 |
| mlp.down_proj    | 1.287        | -          | -         | 4.333 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 2/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 793.002      | -          | -         | 1.584 |
| self_attn.v_proj | 43.677       | -          | -         | 1.225 |
| self_attn.q_proj | 781.086      | -          | -         | 1.277 |
| self_attn.o_proj | 4.861        | -          | -         | 1.506 |
| mlp.up_proj      | 595.458      | -          | -         | 1.574 |
| mlp.gate_proj    | 667.178      | -          | -         | 1.260 |
quantize to 8 bits
| mlp.down_proj    | 1.746        | -          | -         | 4.335 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 3/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 2561.400     | -          | -         | 1.586 |
| self_attn.v_proj | 654.852      | -          | -         | 1.220 |
| self_attn.q_proj | 2343.144     | -          | -         | 1.213 |
| self_attn.o_proj | 10.765       | -          | -         | 1.496 |
| mlp.up_proj      | 1612.238     | -          | -         | 1.519 |
| mlp.gate_proj    | 1846.509     | -          | -         | 1.227 |
| mlp.down_proj    | 34.870       | -          | -         | 4.425 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 4/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 8101.769     | -          | -         | 1.579 |
| self_attn.v_proj | 2151.109     | -          | -         | 1.245 |
| self_attn.q_proj | 7657.171     | -          | -         | 1.243 |
| self_attn.o_proj | 19.905       | -          | -         | 1.489 |
| mlp.up_proj      | 3036.476     | -          | -         | 1.537 |
| mlp.gate_proj    | 3531.977     | -          | -         | 1.252 |
| mlp.down_proj    | 74.489       | -          | -         | 4.484 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 5/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 7960.787     | -          | -         | 1.581 |
| self_attn.v_proj | 2206.618     | -          | -         | 1.265 |
| self_attn.q_proj | 7725.006     | -          | -         | 1.279 |
| self_attn.o_proj | 35.950       | -          | -         | 1.565 |
| mlp.up_proj      | 4133.310     | -          | -         | 1.571 |
| mlp.gate_proj    | 5077.557     | -          | -         | 1.278 |
| mlp.down_proj    | 139.568      | -          | -         | 4.410 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 6/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 9786.277     | -          | -         | 1.622 |
| self_attn.v_proj | 2732.380     | -          | -         | 1.301 |
| self_attn.q_proj | 9013.205     | -          | -         | 1.286 |
| self_attn.o_proj | 66.955       | -          | -         | 1.510 |
| mlp.up_proj      | 5158.774     | -          | -         | 1.584 |
| mlp.gate_proj    | 6406.481     | -          | -         | 1.295 |
| mlp.down_proj    | 203.509      | -          | -         | 4.431 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 7/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 13705.668    | -          | -         | 1.599 |
| self_attn.v_proj | 3889.199     | -          | -         | 1.264 |
| self_attn.q_proj | 13314.186    | -          | -         | 1.250 |
| self_attn.o_proj | 82.158       | -          | -         | 1.562 |
| mlp.up_proj      | 6363.720     | -          | -         | 1.597 |
| mlp.gate_proj    | 8234.826     | -          | -         | 1.284 |
| mlp.down_proj    | 296.776      | -          | -         | 4.414 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 8/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 14663.502    | -          | -         | 1.614 |
| self_attn.v_proj | 4397.724     | -          | -         | 1.296 |
| self_attn.q_proj | 14513.691    | -          | -         | 1.255 |
| self_attn.o_proj | 117.117      | -          | -         | 1.546 |
| mlp.up_proj      | 7405.023     | -          | -         | 1.578 |
| mlp.gate_proj    | 9506.982     | -          | -         | 1.279 |
| mlp.down_proj    | 389.903      | -          | -         | 4.512 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 9/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 14806.180    | -          | -         | 1.639 |
| self_attn.v_proj | 4549.937     | -          | -         | 1.304 |
| self_attn.q_proj | 14559.301    | -          | -         | 1.299 |
| self_attn.o_proj | 172.854      | -          | -         | 1.528 |
| mlp.up_proj      | 8161.521     | -          | -         | 1.619 |
| mlp.gate_proj    | 9910.963     | -          | -         | 1.314 |
| mlp.down_proj    | 477.668      | -          | -         | 4.472 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 10/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 16393.689    | -          | -         | 1.608 |
| self_attn.v_proj | 5051.347     | -          | -         | 1.308 |
| self_attn.q_proj | 15582.259    | -          | -         | 1.276 |
| self_attn.o_proj | 250.973      | -          | -         | 1.567 |
| mlp.up_proj      | 8916.949     | -          | -         | 1.608 |
| mlp.gate_proj    | 10475.550    | -          | -         | 1.267 |
| mlp.down_proj    | 564.673      | -          | -         | 4.446 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 11/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 17370.018    | -          | -         | 1.596 |
| self_attn.v_proj | 5227.794     | -          | -         | 1.273 |
| self_attn.q_proj | 16142.092    | -          | -         | 1.254 |
| self_attn.o_proj | 344.608      | -          | -         | 1.520 |
| mlp.up_proj      | 9569.271     | -          | -         | 1.586 |
| mlp.gate_proj    | 10948.646    | -          | -         | 1.250 |
| mlp.down_proj    | 659.458      | -          | -         | 4.458 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 12/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 18120.143    | -          | -         | 1.619 |
| self_attn.v_proj | 7042.027     | -          | -         | 1.250 |
| self_attn.q_proj | 18162.277    | -          | -         | 1.271 |
| self_attn.o_proj | 359.822      | -          | -         | 1.534 |
| mlp.up_proj      | 10602.450    | -          | -         | 1.579 |
| mlp.gate_proj    | 11848.087    | -          | -         | 1.277 |
| mlp.down_proj    | 757.709      | -          | -         | 4.373 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 13/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 20369.043    | -          | -         | 1.568 |
| self_attn.v_proj | 6970.684     | -          | -         | 1.267 |
| self_attn.q_proj | 19096.055    | -          | -         | 1.253 |
| self_attn.o_proj | 398.790      | -          | -         | 1.506 |
| mlp.up_proj      | 11620.473    | -          | -         | 1.531 |
| mlp.gate_proj    | 12592.637    | -          | -         | 1.226 |
| mlp.down_proj    | 888.741      | -          | -         | 4.331 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 14/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 20367.568    | -          | -         | 1.581 |
| self_attn.v_proj | 7799         | -          | -         | 1.228 |
| self_attn.q_proj | 19529.848    | -          | -         | 1.234 |
| self_attn.o_proj | 452.805      | -          | -         | 1.495 |
| mlp.up_proj      | 12535.656    | -          | -         | 1.544 |
| mlp.gate_proj    | 13233.325    | -          | -         | 1.235 |
| mlp.down_proj    | 1115.207     | -          | -         | 4.318 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 15/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 21156.801    | -          | -         | 1.566 |
| self_attn.v_proj | 7776.499     | -          | -         | 1.207 |
| self_attn.q_proj | 20084.217    | -          | -         | 1.202 |
| self_attn.o_proj | 565.361      | -          | -         | 1.481 |
| mlp.up_proj      | 13850.672    | -          | -         | 1.522 |
| mlp.gate_proj    | 14508.991    | -          | -         | 1.210 |
| mlp.down_proj    | 1334.881     | -          | -         | 4.252 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 16/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 20616.225    | -          | -         | 1.542 |
| self_attn.v_proj | 8162.684     | -          | -         | 1.208 |
| self_attn.q_proj | 19119.686    | -          | -         | 1.221 |
| self_attn.o_proj | 633.609      | -          | -         | 1.447 |
| mlp.up_proj      | 15154.669    | -          | -         | 1.541 |
| mlp.gate_proj    | 15881.895    | -          | -         | 1.198 |
| mlp.down_proj    | 1680.745     | -          | -         | 4.228 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 17/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 21182.969    | -          | -         | 1.549 |
| self_attn.v_proj | 9364.887     | -          | -         | 1.167 |
| self_attn.q_proj | 19959.979    | -          | -         | 1.199 |
| self_attn.o_proj | 850.002      | -          | -         | 1.462 |
| mlp.up_proj      | 16870.029    | -          | -         | 1.528 |
| mlp.gate_proj    | 17932.281    | -          | -         | 1.253 |
| mlp.down_proj    | 2215.731     | -          | -         | 4.374 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 18/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 21658.191    | -          | -         | 1.574 |
| self_attn.v_proj | 9841.971     | -          | -         | 1.239 |
| self_attn.q_proj | 20536.957    | -          | -         | 1.214 |
| self_attn.o_proj | 622.202      | -          | -         | 1.504 |
| mlp.up_proj      | 19262.039    | -          | -         | 1.556 |
| mlp.gate_proj    | 21021.785    | -          | -         | 1.271 |
| mlp.down_proj    | 2511.112     | -          | -         | 4.377 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 19/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 23398.385    | -          | -         | 1.587 |
| self_attn.v_proj | 12218.137    | -          | -         | 1.248 |
| self_attn.q_proj | 22371.375    | -          | -         | 1.251 |
| self_attn.o_proj | 690.034      | -          | -         | 1.496 |
| mlp.up_proj      | 21414.205    | -          | -         | 1.581 |
| mlp.gate_proj    | 23921.635    | -          | -         | 1.264 |
| mlp.down_proj    | 2997.959     | -          | -         | 4.352 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 20/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 22582.424    | -          | -         | 1.562 |
| self_attn.v_proj | 12252.276    | -          | -         | 1.231 |
| self_attn.q_proj | 21668.736    | -          | -         | 1.251 |
| self_attn.o_proj | 675.273      | -          | -         | 1.506 |
| mlp.up_proj      | 23057.633    | -          | -         | 1.573 |
| mlp.gate_proj    | 25968.936    | -          | -         | 1.261 |
| mlp.down_proj    | 3367.933     | -          | -         | 4.295 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 21/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 23173.070    | -          | -         | 1.508 |
| self_attn.v_proj | 12833.449    | -          | -         | 1.174 |
| self_attn.q_proj | 22273.320    | -          | -         | 1.164 |
| self_attn.o_proj | 843.518      | -          | -         | 1.469 |
| mlp.up_proj      | 24173.035    | -          | -         | 1.481 |
| mlp.gate_proj    | 27504.881    | -          | -         | 1.198 |
| mlp.down_proj    | 3942.355     | -          | -         | 4.303 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 22/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 24087.689    | -          | -         | 1.558 |
| self_attn.v_proj | 15025.962    | -          | -         | 1.212 |
| self_attn.q_proj | 23570.363    | -          | -         | 1.225 |
| self_attn.o_proj | 716.688      | -          | -         | 1.509 |
| mlp.up_proj      | 25816.619    | -          | -         | 1.561 |
| mlp.gate_proj    | 29904.094    | -          | -         | 1.262 |
| mlp.down_proj    | 4105.902     | -          | -         | 4.378 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 23/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 25983.168    | -          | -         | 1.596 |
| self_attn.v_proj | 15587.357    | -          | -         | 1.259 |
| self_attn.q_proj | 25335.725    | -          | -         | 1.249 |
| self_attn.o_proj | 933.584      | -          | -         | 1.498 |
| mlp.up_proj      | 27235.479    | -          | -         | 1.548 |
| mlp.gate_proj    | 31976.715    | -          | -         | 1.274 |
| mlp.down_proj    | 4674.150     | -          | -         | 4.370 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 24/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 28279.500    | -          | -         | 1.580 |
| self_attn.v_proj | 19228.578    | -          | -         | 1.225 |
| self_attn.q_proj | 27999.695    | -          | -         | 1.182 |
| self_attn.o_proj | 978.953      | -          | -         | 1.440 |
| mlp.up_proj      | 29546.982    | -          | -         | 1.475 |
| mlp.gate_proj    | 34323.906    | -          | -         | 1.179 |
| mlp.down_proj    | 5053.481     | -          | -         | 4.145 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 25/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 26422.088    | -          | -         | 1.504 |
| self_attn.v_proj | 18542.656    | -          | -         | 1.124 |
| self_attn.q_proj | 26361.676    | -          | -         | 1.158 |
| self_attn.o_proj | 1011.249     | -          | -         | 1.405 |
| mlp.up_proj      | 31390.484    | -          | -         | 1.485 |
| mlp.gate_proj    | 36416.914    | -          | -         | 1.165 |
| mlp.down_proj    | 5391.942     | -          | -         | 4.229 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 26/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 30735.148    | -          | -         | 1.514 |
| self_attn.v_proj | 23209.654    | -          | -         | 1.175 |
| self_attn.q_proj | 30911.730    | -          | -         | 1.149 |
| self_attn.o_proj | 816.281      | -          | -         | 1.437 |
| mlp.up_proj      | 33878.578    | -          | -         | 1.482 |
| mlp.gate_proj    | 39157.781    | -          | -         | 1.170 |
| mlp.down_proj    | 5851.753     | -          | -         | 4.161 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 27/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 29124.834    | -          | -         | 1.483 |
| self_attn.v_proj | 23023.250    | -          | -         | 1.189 |
| self_attn.q_proj | 29269.297    | -          | -         | 1.188 |
| self_attn.o_proj | 1367.783     | -          | -         | 1.433 |
| mlp.up_proj      | 36062.883    | -          | -         | 1.513 |
| mlp.gate_proj    | 41588.340    | -          | -         | 1.205 |
| mlp.down_proj    | 6486.328     | -          | -         | 4.264 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 28/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 32080.672    | -          | -         | 1.518 |
| self_attn.v_proj | 23944.084    | -          | -         | 1.185 |
| self_attn.q_proj | 31985.543    | -          | -         | 1.207 |
| self_attn.o_proj | 1339.910     | -          | -         | 1.440 |
| mlp.up_proj      | 38671.152    | -          | -         | 1.511 |
| mlp.gate_proj    | 44278.367    | -          | -         | 1.198 |
| mlp.down_proj    | 7353.499     | -          | -         | 4.203 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 29/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 31510.570    | -          | -         | 1.561 |
| self_attn.v_proj | 26361.598    | -          | -         | 1.187 |
| self_attn.q_proj | 31639.164    | -          | -         | 1.190 |
| self_attn.o_proj | 1717.708     | -          | -         | 1.477 |
| mlp.up_proj      | 41132.246    | -          | -         | 1.508 |
| mlp.gate_proj    | 45761.105    | -          | -         | 1.230 |
| mlp.down_proj    | 8718.554     | -          | -         | 4.276 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 30/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 27681.590    | -          | -         | 1.528 |
| self_attn.v_proj | 24599.977    | -          | -         | 1.192 |
| self_attn.q_proj | 28589.393    | -          | -         | 1.165 |
| self_attn.o_proj | 1609.514     | -          | -         | 1.456 |
| mlp.up_proj      | 42845.027    | -          | -         | 1.517 |
| mlp.gate_proj    | 47122.930    | -          | -         | 1.208 |
| mlp.down_proj    | 10431.268    | -          | -         | 4.244 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 31/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 29566.197    | -          | -         | 1.509 |
| self_attn.v_proj | 27173.742    | -          | -         | 1.173 |
| self_attn.q_proj | 30452.254    | -          | -         | 1.163 |
| self_attn.o_proj | 1957.387     | -          | -         | 1.471 |
| mlp.up_proj      | 43048.660    | -          | -         | 1.498 |
| mlp.gate_proj    | 47990.305    | -          | -         | 1.209 |
quantize to 8 bits
| mlp.down_proj    | 55.719       | -          | -         | 4.228 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 32/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 21070.355    | -          | -         | 1.543 |
| self_attn.v_proj | 14858.830    | -          | -         | 1.205 |
| self_attn.q_proj | 19984.500    | -          | -         | 1.199 |
| self_attn.o_proj | 2047.994     | -          | -         | 1.450 |
| mlp.up_proj      | 35926.449    | -          | -         | 1.509 |
| mlp.gate_proj    | 40312.195    | -          | -         | 1.194 |
| mlp.down_proj    | 29498.910    | -          | -         | 4.302 |
+------------------+--------------+------------+-----------+-------+


754.2328488826752
wikitext2
PPL:  5.627202987670898
ptb
PPL:  21.424449920654297
c4
PPL:  7.110385417938232
