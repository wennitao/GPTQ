Starting ...
Ready.
Quantizing layer 1/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 6020.791     | -          | -         | 1.689 |
| self_attn.v_proj | 180.202      | -          | -         | 1.221 |
| self_attn.q_proj | 8014.107     | -          | -         | 1.247 |
| self_attn.o_proj | 4.741        | -          | -         | 1.460 |
| mlp.up_proj      | 4349.743     | -          | -         | 1.555 |
| mlp.gate_proj    | 4515.372     | -          | -         | 1.249 |
| mlp.down_proj    | 43.647       | -          | -         | 4.312 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 2/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 26186.391    | -          | -         | 1.521 |
| self_attn.v_proj | 1235.167     | -          | -         | 1.208 |
| self_attn.q_proj | 26588.799    | -          | -         | 1.218 |
| self_attn.o_proj | 124.909      | -          | -         | 1.486 |
| mlp.up_proj      | 18382.549    | -          | -         | 1.562 |
| mlp.gate_proj    | 20729.637    | -          | -         | 1.244 |
| mlp.down_proj    | 170469.609   | -          | -         | 4.345 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 3/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 61377.523    | -          | -         | 1.577 |
| self_attn.v_proj | 14547.184    | -          | -         | 1.240 |
| self_attn.q_proj | 57605.102    | -          | -         | 1.228 |
| self_attn.o_proj | 238.737      | -          | -         | 1.495 |
| mlp.up_proj      | 31645.395    | -          | -         | 1.552 |
| mlp.gate_proj    | 36402.672    | -          | -         | 1.245 |
| mlp.down_proj    | 515.027      | -          | -         | 4.352 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 4/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 181205.594   | -          | -         | 1.581 |
| self_attn.v_proj | 46420.047    | -          | -         | 1.247 |
| self_attn.q_proj | 175371.797   | -          | -         | 1.238 |
| self_attn.o_proj | 336.143      | -          | -         | 1.493 |
| mlp.up_proj      | 72380.742    | -          | -         | 1.536 |
| mlp.gate_proj    | 84384.992    | -          | -         | 1.252 |
| mlp.down_proj    | 1512.616     | -          | -         | 4.334 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 5/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 199361.109   | -          | -         | 1.560 |
| self_attn.v_proj | 53104.059    | -          | -         | 1.216 |
| self_attn.q_proj | 197288.875   | -          | -         | 1.222 |
| self_attn.o_proj | 596.648      | -          | -         | 1.503 |
| mlp.up_proj      | 103515.844   | -          | -         | 1.545 |
| mlp.gate_proj    | 127467.984   | -          | -         | 1.259 |
| mlp.down_proj    | 3017.748     | -          | -         | 4.380 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 6/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 251123.406   | -          | -         | 1.603 |
| self_attn.v_proj | 68066.805    | -          | -         | 1.288 |
| self_attn.q_proj | 234465.078   | -          | -         | 1.245 |
| self_attn.o_proj | 1313.070     | -          | -         | 1.498 |
| mlp.up_proj      | 132891.641   | -          | -         | 1.555 |
| mlp.gate_proj    | 165508.875   | -          | -         | 1.268 |
| mlp.down_proj    | 4672.198     | -          | -         | 4.407 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 7/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 355453.250   | -          | -         | 1.579 |
| self_attn.v_proj | 99229.125    | -          | -         | 1.235 |
| self_attn.q_proj | 350601.938   | -          | -         | 1.253 |
| self_attn.o_proj | 1992.853     | -          | -         | 1.542 |
| mlp.up_proj      | 157413.719   | -          | -         | 1.579 |
| mlp.gate_proj    | 204479.609   | -          | -         | 1.265 |
| mlp.down_proj    | 6540.293     | -          | -         | 4.424 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 8/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 373710.125   | -          | -         | 1.598 |
| self_attn.v_proj | 110676.344   | -          | -         | 1.248 |
| self_attn.q_proj | 374467.312   | -          | -         | 1.233 |
| self_attn.o_proj | 2780.433     | -          | -         | 1.484 |
| mlp.up_proj      | 188614       | -          | -         | 1.559 |
| mlp.gate_proj    | 242770.094   | -          | -         | 1.247 |
| mlp.down_proj    | 8647.994     | -          | -         | 4.368 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 9/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 383424.188   | -          | -         | 1.583 |
| self_attn.v_proj | 116513.625   | -          | -         | 1.256 |
| self_attn.q_proj | 380985.938   | -          | -         | 1.235 |
| self_attn.o_proj | 4209.184     | -          | -         | 1.500 |
| mlp.up_proj      | 208469.312   | -          | -         | 1.542 |
| mlp.gate_proj    | 253797.031   | -          | -         | 1.231 |
| mlp.down_proj    | 10974.708    | -          | -         | 4.364 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 10/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 424620.125   | -          | -         | 1.569 |
| self_attn.v_proj | 129649.398   | -          | -         | 1.250 |
| self_attn.q_proj | 403354.062   | -          | -         | 1.247 |
| self_attn.o_proj | 5248.182     | -          | -         | 1.486 |
| mlp.up_proj      | 226953.172   | -          | -         | 1.566 |
| mlp.gate_proj    | 267251.188   | -          | -         | 1.246 |
| mlp.down_proj    | 12982.079    | -          | -         | 4.318 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 11/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 441793.312   | -          | -         | 1.624 |
| self_attn.v_proj | 131434.391   | -          | -         | 1.273 |
| self_attn.q_proj | 411637.188   | -          | -         | 1.249 |
| self_attn.o_proj | 7277.324     | -          | -         | 1.517 |
| mlp.up_proj      | 239654.719   | -          | -         | 1.584 |
| mlp.gate_proj    | 274723.938   | -          | -         | 1.259 |
| mlp.down_proj    | 14504.111    | -          | -         | 4.328 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 12/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 453900       | -          | -         | 1.578 |
| self_attn.v_proj | 173624.266   | -          | -         | 1.233 |
| self_attn.q_proj | 454059.312   | -          | -         | 1.240 |
| self_attn.o_proj | 8040.868     | -          | -         | 1.518 |
| mlp.up_proj      | 267056.531   | -          | -         | 1.560 |
| mlp.gate_proj    | 298829.281   | -          | -         | 1.265 |
| mlp.down_proj    | 16047.570    | -          | -         | 4.346 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 13/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 516357.625   | -          | -         | 1.582 |
| self_attn.v_proj | 173667.219   | -          | -         | 1.257 |
| self_attn.q_proj | 483332.188   | -          | -         | 1.274 |
| self_attn.o_proj | 7146.603     | -          | -         | 1.512 |
| mlp.up_proj      | 294494.812   | -          | -         | 1.585 |
| mlp.gate_proj    | 319441.719   | -          | -         | 1.258 |
| mlp.down_proj    | 19109.840    | -          | -         | 4.372 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 14/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 515982.500   | -          | -         | 1.589 |
| self_attn.v_proj | 195880.594   | -          | -         | 1.230 |
| self_attn.q_proj | 500555.938   | -          | -         | 1.278 |
| self_attn.o_proj | 8530.855     | -          | -         | 1.529 |
| mlp.up_proj      | 320386.875   | -          | -         | 1.589 |
| mlp.gate_proj    | 338903.219   | -          | -         | 1.270 |
| mlp.down_proj    | 24053.477    | -          | -         | 4.381 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 15/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 547195.250   | -          | -         | 1.592 |
| self_attn.v_proj | 198597.047   | -          | -         | 1.217 |
| self_attn.q_proj | 520179.375   | -          | -         | 1.259 |
| self_attn.o_proj | 11944.364    | -          | -         | 1.524 |
| mlp.up_proj      | 351308.938   | -          | -         | 1.578 |
| mlp.gate_proj    | 368561.188   | -          | -         | 1.264 |
| mlp.down_proj    | 28690.939    | -          | -         | 4.368 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 16/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 534303.188   | -          | -         | 1.583 |
| self_attn.v_proj | 208183.531   | -          | -         | 1.263 |
| self_attn.q_proj | 499187.375   | -          | -         | 1.265 |
| self_attn.o_proj | 14222.441    | -          | -         | 1.518 |
| mlp.up_proj      | 384277.688   | -          | -         | 1.575 |
| mlp.gate_proj    | 403281.750   | -          | -         | 1.281 |
| mlp.down_proj    | 37210.637    | -          | -         | 4.402 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 17/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 555298.250   | -          | -         | 1.610 |
| self_attn.v_proj | 240962.422   | -          | -         | 1.268 |
| self_attn.q_proj | 526252.938   | -          | -         | 1.276 |
| self_attn.o_proj | 19602.039    | -          | -         | 1.526 |
| mlp.up_proj      | 431071.188   | -          | -         | 1.566 |
| mlp.gate_proj    | 458843.688   | -          | -         | 1.237 |
| mlp.down_proj    | 47365.438    | -          | -         | 4.345 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 18/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 551496.062   | -          | -         | 1.576 |
| self_attn.v_proj | 246847.531   | -          | -         | 1.234 |
| self_attn.q_proj | 529600.312   | -          | -         | 1.263 |
| self_attn.o_proj | 14484.377    | -          | -         | 1.518 |
| mlp.up_proj      | 495601.781   | -          | -         | 1.581 |
| mlp.gate_proj    | 541573.375   | -          | -         | 1.236 |
| mlp.down_proj    | 54747.199    | -          | -         | 4.397 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 19/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 602948       | -          | -         | 1.596 |
| self_attn.v_proj | 310945.938   | -          | -         | 1.226 |
| self_attn.q_proj | 584761.750   | -          | -         | 1.254 |
| self_attn.o_proj | 15873.287    | -          | -         | 1.494 |
| mlp.up_proj      | 552562.375   | -          | -         | 1.595 |
| mlp.gate_proj    | 618638.750   | -          | -         | 1.259 |
| mlp.down_proj    | 66729.562    | -          | -         | 4.400 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 20/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 583161.625   | -          | -         | 1.601 |
| self_attn.v_proj | 312505.500   | -          | -         | 1.237 |
| self_attn.q_proj | 566136.375   | -          | -         | 1.241 |
| self_attn.o_proj | 15915.107    | -          | -         | 1.523 |
| mlp.up_proj      | 594301.688   | -          | -         | 1.601 |
| mlp.gate_proj    | 669997.188   | -          | -         | 1.259 |
| mlp.down_proj    | 75447.453    | -          | -         | 4.326 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 21/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 601470.250   | -          | -         | 1.591 |
| self_attn.v_proj | 328705       | -          | -         | 1.227 |
| self_attn.q_proj | 586615.375   | -          | -         | 1.250 |
| self_attn.o_proj | 20666.387    | -          | -         | 1.528 |
| mlp.up_proj      | 629980.250   | -          | -         | 1.570 |
| mlp.gate_proj    | 718897.750   | -          | -         | 1.227 |
| mlp.down_proj    | 87174.266    | -          | -         | 4.378 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 22/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 627423.500   | -          | -         | 1.588 |
| self_attn.v_proj | 387005.469   | -          | -         | 1.216 |
| self_attn.q_proj | 620484.250   | -          | -         | 1.247 |
| self_attn.o_proj | 20253.359    | -          | -         | 1.493 |
| mlp.up_proj      | 675479.500   | -          | -         | 1.570 |
| mlp.gate_proj    | 784149       | -          | -         | 1.272 |
| mlp.down_proj    | 93572.812    | -          | -         | 4.359 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 23/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 680358.250   | -          | -         | 1.579 |
| self_attn.v_proj | 404617.562   | -          | -         | 1.244 |
| self_attn.q_proj | 670064.125   | -          | -         | 1.258 |
| self_attn.o_proj | 27866.113    | -          | -         | 1.490 |
| mlp.up_proj      | 705227.625   | -          | -         | 1.548 |
| mlp.gate_proj    | 829100.312   | -          | -         | 1.263 |
| mlp.down_proj    | 101647.172   | -          | -         | 4.441 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 24/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 732413.625   | -          | -         | 1.614 |
| self_attn.v_proj | 493433.281   | -          | -         | 1.272 |
| self_attn.q_proj | 727542.125   | -          | -         | 1.236 |
| self_attn.o_proj | 19919.227    | -          | -         | 1.502 |
| mlp.up_proj      | 760730.062   | -          | -         | 1.543 |
| mlp.gate_proj    | 884479.125   | -          | -         | 1.287 |
| mlp.down_proj    | 112953.938   | -          | -         | 4.365 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 25/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 678462       | -          | -         | 1.563 |
| self_attn.v_proj | 471574.906   | -          | -         | 1.250 |
| self_attn.q_proj | 672634.625   | -          | -         | 1.230 |
| self_attn.o_proj | 27038.590    | -          | -         | 1.519 |
| mlp.up_proj      | 796814.500   | -          | -         | 1.578 |
| mlp.gate_proj    | 925443.250   | -          | -         | 1.271 |
| mlp.down_proj    | 119335.172   | -          | -         | 4.409 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 26/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 775822.500   | -          | -         | 1.599 |
| self_attn.v_proj | 582590.188   | -          | -         | 1.267 |
| self_attn.q_proj | 774714.250   | -          | -         | 1.250 |
| self_attn.o_proj | 18723.965    | -          | -         | 1.533 |
| mlp.up_proj      | 851279.875   | -          | -         | 1.561 |
| mlp.gate_proj    | 984949.875   | -          | -         | 1.254 |
| mlp.down_proj    | 131972.469   | -          | -         | 4.350 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 27/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 743576       | -          | -         | 1.571 |
| self_attn.v_proj | 583470.438   | -          | -         | 1.215 |
| self_attn.q_proj | 737114.875   | -          | -         | 1.221 |
| self_attn.o_proj | 35727.398    | -          | -         | 1.484 |
| mlp.up_proj      | 910363.250   | -          | -         | 1.545 |
| mlp.gate_proj    | 1050922.125  | -          | -         | 1.237 |
| mlp.down_proj    | 149208.469   | -          | -         | 4.364 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 28/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 811748.188   | -          | -         | 1.592 |
| self_attn.v_proj | 603973       | -          | -         | 1.258 |
| self_attn.q_proj | 806349       | -          | -         | 1.276 |
| self_attn.o_proj | 26996.619    | -          | -         | 1.502 |
| mlp.up_proj      | 982541.562   | -          | -         | 1.596 |
| mlp.gate_proj    | 1126220      | -          | -         | 1.258 |
| mlp.down_proj    | 174046.312   | -          | -         | 4.433 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 29/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 812004.500   | -          | -         | 1.571 |
| self_attn.v_proj | 675957.375   | -          | -         | 1.190 |
| self_attn.q_proj | 803787.562   | -          | -         | 1.223 |
| self_attn.o_proj | 35224.285    | -          | -         | 1.493 |
| mlp.up_proj      | 1063137.500  | -          | -         | 1.572 |
| mlp.gate_proj    | 1183978.500  | -          | -         | 1.256 |
| mlp.down_proj    | 219145.719   | -          | -         | 4.363 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 30/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 725671.875   | -          | -         | 1.586 |
| self_attn.v_proj | 640517.750   | -          | -         | 1.224 |
| self_attn.q_proj | 726415       | -          | -         | 1.233 |
| self_attn.o_proj | 38779.699    | -          | -         | 1.452 |
| mlp.up_proj      | 1126738.500  | -          | -         | 1.577 |
| mlp.gate_proj    | 1239293.500  | -          | -         | 1.243 |
| mlp.down_proj    | 287992.625   | -          | -         | 4.231 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 31/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 783034.500   | -          | -         | 1.537 |
| self_attn.v_proj | 717669.188   | -          | -         | 1.225 |
| self_attn.q_proj | 778118.562   | -          | -         | 1.211 |
| self_attn.o_proj | 41550.461    | -          | -         | 1.490 |
| mlp.up_proj      | 1164923.750  | -          | -         | 1.589 |
| mlp.gate_proj    | 1298233.625  | -          | -         | 1.285 |
| mlp.down_proj    | 477344.281   | -          | -         | 4.395 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 32/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 572387       | -          | -         | 1.606 |
| self_attn.v_proj | 400500.906   | -          | -         | 1.259 |
| self_attn.q_proj | 538355.125   | -          | -         | 1.264 |
| self_attn.o_proj | 64564.469    | -          | -         | 1.476 |
| mlp.up_proj      | 975708.500   | -          | -         | 1.519 |
| mlp.gate_proj    | 1095754.375  | -          | -         | 1.219 |
| mlp.down_proj    | 1019104.312  | -          | -         | 4.289 |
+------------------+--------------+------------+-----------+-------+


757.6549656391144
wikitext2
PPL:  42.40616226196289
ptb
PPL:  nan
c4
PPL:  37.024925231933594
