Starting ...
Ready.
Quantizing layer 1/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 182.349      | 0.000      | 0.001     | 1.688 |
| self_attn.v_proj | 7.743        | 0.001      | 0.070     | 1.240 |
| self_attn.q_proj | 206.937      | 0.000      | 0.000     | 1.288 |
| self_attn.o_proj | 0.145        | 0.000      | 0.003     | 1.554 |
| mlp.up_proj      | 146.115      | 0.001      | 0.004     | 1.582 |
| mlp.gate_proj    | 150.995      | 0.001      | 0.003     | 1.281 |
| mlp.down_proj    | 1.287        | 0.001      | 0.200     | 4.421 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 2/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 793.002      | 0.000      | 0.002     | 1.596 |
| self_attn.v_proj | 43.677       | 0.001      | 0.047     | 1.243 |
| self_attn.q_proj | 781.086      | 0.000      | 0.002     | 1.241 |
| self_attn.o_proj | 4.861        | 0.002      | 0.020     | 1.528 |
| mlp.up_proj      | 595.458      | 0.002      | 0.004     | 1.590 |
| mlp.gate_proj    | 667.178      | 0.001      | 0.002     | 1.250 |
| mlp.down_proj    | 444.357      | 0.000      | 0.001     | 4.426 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 3/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 2565.903     | 0.000      | 0.000     | 1.574 |
| self_attn.v_proj | 655.205      | 0.002      | 0.009     | 1.236 |
| self_attn.q_proj | 2346.053     | 0.000      | 0.001     | 1.270 |
| self_attn.o_proj | 10.493       | 0.004      | 0.011     | 1.520 |
| mlp.up_proj      | 1611.481     | 0.004      | 0.014     | 1.530 |
| mlp.gate_proj    | 1845.661     | 0.002      | 0.009     | 1.249 |
| mlp.down_proj    | 34.489       | 0.004      | 0.196     | 4.415 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 4/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 8082.769     | 0.000      | 0.001     | 1.590 |
| self_attn.v_proj | 2145.831     | 0.004      | 0.008     | 1.281 |
| self_attn.q_proj | 7636.438     | 0.001      | 0.001     | 1.300 |
| self_attn.o_proj | 19.231       | 0.003      | 0.012     | 1.515 |
| mlp.up_proj      | 3042.344     | 0.005      | 0.008     | 1.582 |
| mlp.gate_proj    | 3537.880     | 0.003      | 0.005     | 1.255 |
| mlp.down_proj    | 73.913       | 0.005      | 0.046     | 4.404 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 5/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 7978.500     | 0.000      | 0.001     | 1.601 |
| self_attn.v_proj | 2211.744     | 0.004      | 0.009     | 1.265 |
| self_attn.q_proj | 7738.333     | 0.001      | 0.001     | 1.249 |
| self_attn.o_proj | 35.664       | 0.003      | 0.009     | 1.528 |
| mlp.up_proj      | 4142.168     | 0.005      | 0.014     | 1.558 |
| mlp.gate_proj    | 5088.745     | 0.003      | 0.008     | 1.242 |
| mlp.down_proj    | 139.093      | 0.005      | 0.318     | 4.378 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 6/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 9795.246     | 0.000      | 0.001     | 1.586 |
| self_attn.v_proj | 2733.263     | 0.004      | 0.010     | 1.246 |
| self_attn.q_proj | 9019.172     | 0.001      | 0.002     | 1.244 |
| self_attn.o_proj | 66.949       | 0.004      | 0.010     | 1.509 |
| mlp.up_proj      | 5200.742     | 0.005      | 0.009     | 1.587 |
| mlp.gate_proj    | 6462.293     | 0.003      | 0.005     | 1.275 |
| mlp.down_proj    | 206.154      | 0.006      | 0.111     | 4.425 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 7/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 13734.025    | 0.001      | 0.001     | 1.582 |
| self_attn.v_proj | 3895.990     | 0.004      | 0.009     | 1.256 |
| self_attn.q_proj | 13338.701    | 0.001      | 0.002     | 1.249 |
| self_attn.o_proj | 84.165       | 0.004      | 0.009     | 1.465 |
| mlp.up_proj      | 6366.930     | 0.005      | 0.008     | 1.543 |
| mlp.gate_proj    | 8234.774     | 0.002      | 0.004     | 1.241 |
| mlp.down_proj    | 302.637      | 0.005      | 0.098     | 4.285 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 8/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 14689.331    | 0.001      | 0.002     | 1.536 |
| self_attn.v_proj | 4406.467     | 0.004      | 0.009     | 1.241 |
| self_attn.q_proj | 14537.940    | 0.001      | 0.002     | 1.232 |
| self_attn.o_proj | 117.394      | 0.004      | 0.009     | 1.487 |
| mlp.up_proj      | 7429.443     | 0.005      | 0.009     | 1.525 |
| mlp.gate_proj    | 9539.909     | 0.002      | 0.004     | 1.274 |
| mlp.down_proj    | 396.253      | 0.005      | 0.197     | 4.335 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 9/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 14855.452    | 0.001      | 0.003     | 1.557 |
| self_attn.v_proj | 4562.165     | 0.004      | 0.016     | 1.249 |
| self_attn.q_proj | 14613.965    | 0.001      | 0.004     | 1.228 |
| self_attn.o_proj | 173.500      | 0.005      | 0.009     | 1.511 |
| mlp.up_proj      | 8180.319     | 0.004      | 0.010     | 1.546 |
| mlp.gate_proj    | 9934.236     | 0.002      | 0.006     | 1.255 |
| mlp.down_proj    | 482.349      | 0.006      | 0.299     | 4.346 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 10/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 16457.053    | 0.001      | 0.004     | 1.592 |
| self_attn.v_proj | 5074.290     | 0.004      | 0.022     | 1.239 |
| self_attn.q_proj | 15628.414    | 0.001      | 0.006     | 1.239 |
| self_attn.o_proj | 251.855      | 0.005      | 0.008     | 1.514 |
| mlp.up_proj      | 8964.922     | 0.004      | 0.014     | 1.570 |
| mlp.gate_proj    | 10531.066    | 0.002      | 0.007     | 1.251 |
| mlp.down_proj    | 567.484      | 0.006      | 0.156     | 4.280 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 11/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 17407.189    | 0.001      | 0.007     | 1.540 |
| self_attn.v_proj | 5247.023     | 0.004      | 0.036     | 1.216 |
| self_attn.q_proj | 16194.236    | 0.001      | 0.010     | 1.209 |
| self_attn.o_proj | 344.841      | 0.005      | 0.007     | 1.479 |
| mlp.up_proj      | 9612.996     | 0.004      | 0.007     | 1.542 |
| mlp.gate_proj    | 10998.793    | 0.002      | 0.004     | 1.215 |
| mlp.down_proj    | 661.917      | 0.006      | 0.028     | 4.276 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 12/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 18179.830    | 0.001      | 0.005     | 1.550 |
| self_attn.v_proj | 7064.566     | 0.004      | 0.023     | 1.204 |
| self_attn.q_proj | 18217.193    | 0.001      | 0.006     | 1.206 |
| self_attn.o_proj | 359.813      | 0.005      | 0.008     | 1.438 |
| mlp.up_proj      | 10657.141    | 0.004      | 0.007     | 1.513 |
| mlp.gate_proj    | 11906.809    | 0.002      | 0.004     | 1.216 |
| mlp.down_proj    | 755.079      | 0.006      | 0.024     | 4.308 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 13/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 20451.102    | 0.001      | 0.005     | 1.526 |
| self_attn.v_proj | 7004.195     | 0.005      | 0.024     | 1.207 |
| self_attn.q_proj | 19175.930    | 0.001      | 0.007     | 1.172 |
| self_attn.o_proj | 397.933      | 0.005      | 0.009     | 1.472 |
| mlp.up_proj      | 11666.318    | 0.005      | 0.009     | 1.509 |
| mlp.gate_proj    | 12640.365    | 0.003      | 0.005     | 1.255 |
| mlp.down_proj    | 882.957      | 0.006      | 0.048     | 4.384 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 14/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 20407.258    | 0.001      | 0.004     | 1.535 |
| self_attn.v_proj | 7813.370     | 0.005      | 0.020     | 1.202 |
| self_attn.q_proj | 19580.438    | 0.001      | 0.005     | 1.184 |
| self_attn.o_proj | 453.214      | 0.005      | 0.008     | 1.478 |
| mlp.up_proj      | 12558.368    | 0.004      | 0.010     | 1.565 |
| mlp.gate_proj    | 13257.225    | 0.002      | 0.005     | 1.240 |
| mlp.down_proj    | 1111.432     | 0.006      | 0.049     | 4.244 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 15/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 21162.203    | 0.001      | 0.004     | 1.523 |
| self_attn.v_proj | 7783.560     | 0.005      | 0.021     | 1.185 |
| self_attn.q_proj | 20091.654    | 0.001      | 0.006     | 1.213 |
| self_attn.o_proj | 573.095      | 0.006      | 0.007     | 1.480 |
| mlp.up_proj      | 13822.148    | 0.005      | 0.009     | 1.524 |
| mlp.gate_proj    | 14487.154    | 0.003      | 0.005     | 1.354 |
| mlp.down_proj    | 1327.950     | 0.007      | 0.050     | 4.271 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 16/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 20592.291    | 0.001      | 0.004     | 1.536 |
| self_attn.v_proj | 8149.160     | 0.005      | 0.019     | 1.193 |
| self_attn.q_proj | 19332.410    | 0.001      | 0.005     | 1.201 |
| self_attn.o_proj | 629.852      | 0.005      | 0.009     | 1.456 |
| mlp.up_proj      | 15135.765    | 0.004      | 0.009     | 1.524 |
| mlp.gate_proj    | 15852.453    | 0.003      | 0.005     | 1.207 |
| mlp.down_proj    | 1674.710     | 0.007      | 0.069     | 4.238 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 17/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 21154.113    | 0.001      | 0.003     | 1.576 |
| self_attn.v_proj | 9344.564     | 0.006      | 0.020     | 1.183 |
| self_attn.q_proj | 19933.146    | 0.001      | 0.005     | 1.200 |
| self_attn.o_proj | 848.368      | 0.005      | 0.007     | 1.453 |
| mlp.up_proj      | 16849.082    | 0.004      | 0.008     | 1.529 |
| mlp.gate_proj    | 17899.459    | 0.002      | 0.005     | 1.249 |
| mlp.down_proj    | 2213.800     | 0.006      | 0.133     | 4.295 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 18/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 21611.762    | 0.001      | 0.002     | 1.539 |
| self_attn.v_proj | 9826.848     | 0.005      | 0.013     | 1.262 |
| self_attn.q_proj | 20504.176    | 0.001      | 0.003     | 1.187 |
| self_attn.o_proj | 620.616      | 0.005      | 0.008     | 1.453 |
| mlp.up_proj      | 19224.365    | 0.005      | 0.008     | 1.534 |
| mlp.gate_proj    | 20975.115    | 0.003      | 0.004     | 1.219 |
| mlp.down_proj    | 2500.950     | 0.006      | 0.071     | 4.353 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 19/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 23352.258    | 0.001      | 0.003     | 1.554 |
| self_attn.v_proj | 12207.814    | 0.005      | 0.015     | 1.211 |
| self_attn.q_proj | 22337.348    | 0.001      | 0.004     | 1.191 |
| self_attn.o_proj | 687.514      | 0.005      | 0.011     | 1.480 |
| mlp.up_proj      | 21384.285    | 0.005      | 0.008     | 1.503 |
| mlp.gate_proj    | 23892.406    | 0.003      | 0.004     | 1.213 |
| mlp.down_proj    | 2983.017     | 0.006      | 0.118     | 4.326 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 20/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 22571.697    | 0.001      | 0.002     | 1.552 |
| self_attn.v_proj | 12244.846    | 0.005      | 0.012     | 1.370 |
| self_attn.q_proj | 21637.039    | 0.001      | 0.003     | 1.180 |
| self_attn.o_proj | 671.584      | 0.005      | 0.008     | 1.483 |
| mlp.up_proj      | 23020.246    | 0.005      | 0.008     | 1.532 |
| mlp.gate_proj    | 25917.977    | 0.003      | 0.005     | 1.221 |
| mlp.down_proj    | 3351.030     | 0.006      | 0.280     | 4.306 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 21/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 23157.086    | 0.001      | 0.002     | 1.549 |
| self_attn.v_proj | 12806.840    | 0.006      | 0.012     | 1.181 |
| self_attn.q_proj | 22654.039    | 0.001      | 0.003     | 1.210 |
| self_attn.o_proj | 841.582      | 0.003      | 0.006     | 1.465 |
| mlp.up_proj      | 24120.541    | 0.005      | 0.007     | 1.528 |
| mlp.gate_proj    | 27458.762    | 0.003      | 0.004     | 1.215 |
| mlp.down_proj    | 3919.379     | 0.006      | 0.074     | 4.380 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 22/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 24034.291    | 0.001      | 0.002     | 1.578 |
| self_attn.v_proj | 14987.139    | 0.006      | 0.011     | 1.245 |
| self_attn.q_proj | 23510.697    | 0.002      | 0.003     | 1.239 |
| self_attn.o_proj | 725.631      | 0.004      | 0.007     | 1.503 |
| mlp.up_proj      | 25739.082    | 0.005      | 0.007     | 1.571 |
| mlp.gate_proj    | 29812.947    | 0.003      | 0.005     | 1.229 |
| mlp.down_proj    | 4072.058     | 0.006      | 0.079     | 4.344 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 23/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 25914.004    | 0.001      | 0.002     | 1.562 |
| self_attn.v_proj | 15553.372    | 0.006      | 0.010     | 1.229 |
| self_attn.q_proj | 25258.273    | 0.001      | 0.003     | 1.219 |
| self_attn.o_proj | 932.323      | 0.004      | 0.010     | 1.463 |
| mlp.up_proj      | 27150.211    | 0.005      | 0.007     | 1.553 |
| mlp.gate_proj    | 31869.490    | 0.003      | 0.005     | 1.281 |
| mlp.down_proj    | 4632.464     | 0.006      | 0.063     | 4.364 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 24/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 28194.662    | 0.001      | 0.002     | 1.578 |
| self_attn.v_proj | 19165.855    | 0.006      | 0.010     | 1.234 |
| self_attn.q_proj | 27907.125    | 0.002      | 0.003     | 1.216 |
| self_attn.o_proj | 977.460      | 0.005      | 0.010     | 1.480 |
| mlp.up_proj      | 29464.145    | 0.005      | 0.007     | 1.572 |
| mlp.gate_proj    | 34225.254    | 0.004      | 0.005     | 1.268 |
| mlp.down_proj    | 5016.461     | 0.006      | 0.127     | 4.339 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 25/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 26357.184    | 0.001      | 0.002     | 1.554 |
| self_attn.v_proj | 18518.395    | 0.006      | 0.011     | 1.236 |
| self_attn.q_proj | 26319.223    | 0.002      | 0.003     | 1.242 |
| self_attn.o_proj | 1014.737     | 0.004      | 0.008     | 1.473 |
| mlp.up_proj      | 31336.875    | 0.006      | 0.008     | 1.567 |
| mlp.gate_proj    | 36352.875    | 0.004      | 0.006     | 1.291 |
| mlp.down_proj    | 5367.703     | 0.007      | 0.101     | 4.362 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 26/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 30664        | 0.001      | 0.002     | 1.581 |
| self_attn.v_proj | 23175.461    | 0.006      | 0.010     | 1.234 |
| self_attn.q_proj | 30865.645    | 0.002      | 0.003     | 1.244 |
| self_attn.o_proj | 823.546      | 0.005      | 0.012     | 1.487 |
| mlp.up_proj      | 33789.934    | 0.006      | 0.008     | 1.543 |
| mlp.gate_proj    | 39067.656    | 0.004      | 0.005     | 1.270 |
| mlp.down_proj    | 5823.646     | 0.007      | 0.101     | 4.329 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 27/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 29081.150    | 0.001      | 0.002     | 1.538 |
| self_attn.v_proj | 22997.215    | 0.006      | 0.012     | 1.214 |
| self_attn.q_proj | 29209.996    | 0.002      | 0.003     | 1.286 |
| self_attn.o_proj | 1376.841     | 0.003      | 0.006     | 1.514 |
| mlp.up_proj      | 36003.320    | 0.005      | 0.008     | 1.588 |
| mlp.gate_proj    | 41528.125    | 0.003      | 0.005     | 1.293 |
| mlp.down_proj    | 6459.332     | 0.007      | 0.153     | 4.450 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 28/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 31995.322    | 0.001      | 0.002     | 1.619 |
| self_attn.v_proj | 23902.082    | 0.006      | 0.009     | 1.267 |
| self_attn.q_proj | 31917.311    | 0.002      | 0.003     | 1.272 |
| self_attn.o_proj | 1343.530     | 0.005      | 0.021     | 1.522 |
| mlp.up_proj      | 38600.137    | 0.005      | 0.007     | 1.588 |
| mlp.gate_proj    | 44196.207    | 0.003      | 0.005     | 1.288 |
| mlp.down_proj    | 7320.839     | 0.007      | 0.128     | 4.440 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 29/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 31446.244    | 0.001      | 0.002     | 1.618 |
| self_attn.v_proj | 26314.123    | 0.006      | 0.009     | 1.271 |
| self_attn.q_proj | 31591.215    | 0.002      | 0.003     | 1.275 |
| self_attn.o_proj | 1714.556     | 0.004      | 0.010     | 1.526 |
| mlp.up_proj      | 41086.469    | 0.004      | 0.006     | 1.592 |
| mlp.gate_proj    | 45704.352    | 0.003      | 0.005     | 1.284 |
| mlp.down_proj    | 8676.642     | 0.006      | 0.108     | 4.423 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 30/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 27640.012    | 0.001      | 0.002     | 1.598 |
| self_attn.v_proj | 24563.473    | 0.006      | 0.010     | 1.258 |
| self_attn.q_proj | 28527.668    | 0.002      | 0.003     | 1.259 |
| self_attn.o_proj | 1606.273     | 0.003      | 0.007     | 1.542 |
| mlp.up_proj      | 42815.773    | 0.003      | 0.005     | 1.616 |
| mlp.gate_proj    | 47030.266    | 0.003      | 0.005     | 1.297 |
| mlp.down_proj    | 10390.432    | 0.006      | 0.145     | 4.478 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 31/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 29533.303    | 0.001      | 0.002     | 1.607 |
| self_attn.v_proj | 27140.162    | 0.006      | 0.008     | 1.254 |
| self_attn.q_proj | 30437.383    | 0.002      | 0.003     | 1.288 |
| self_attn.o_proj | 1950.979     | 0.004      | 0.014     | 1.502 |
| mlp.up_proj      | 43075.492    | 0.002      | 0.005     | 1.567 |
| mlp.gate_proj    | 48027.406    | 0.002      | 0.005     | 1.340 |
| mlp.down_proj    | 17256.693    | 0.001      | 0.231     | 4.533 |
+------------------+--------------+------------+-----------+-------+


Quantizing layer 32/32..
+------------------+--------------+------------+-----------+-------+
|       name       | weight_error | fp_inp_SNR | q_inp_SNR | time  |
+==================+==============+============+===========+=======+
| self_attn.k_proj | 21060.955    | 0.001      | 0.001     | 1.643 |
| self_attn.v_proj | 14855.664    | 0.006      | 0.008     | 1.277 |
| self_attn.q_proj | 19978.504    | 0.001      | 0.002     | 1.289 |
| self_attn.o_proj | 2070.730     | 0.002      | 0.005     | 1.520 |
| mlp.up_proj      | 35895.352    | 0.001      | 0.003     | 1.590 |
| mlp.gate_proj    | 40273.055    | 0.001      | 0.004     | 1.247 |
| mlp.down_proj    | 29448.596    | 0.001      | 0.010     | 4.441 |
+------------------+--------------+------------+-----------+-------+


+---------------------+-----------+
|        name         |   error   |
+=====================+===========+
| mlp.gate_proj.30    | 48027.406 |
+---------------------+-----------+
| mlp.gate_proj.29    | 47030.266 |
+---------------------+-----------+
| mlp.gate_proj.28    | 45704.352 |
+---------------------+-----------+
| mlp.gate_proj.27    | 44196.207 |
+---------------------+-----------+
| mlp.up_proj.30      | 43075.492 |
+---------------------+-----------+
| mlp.up_proj.29      | 42815.773 |
+---------------------+-----------+
| mlp.gate_proj.26    | 41528.125 |
+---------------------+-----------+
| mlp.up_proj.28      | 41086.469 |
+---------------------+-----------+
| mlp.gate_proj.31    | 40273.055 |
+---------------------+-----------+
| mlp.gate_proj.25    | 39067.656 |
+---------------------+-----------+
| mlp.up_proj.27      | 38600.137 |
+---------------------+-----------+
| mlp.gate_proj.24    | 36352.875 |
+---------------------+-----------+
| mlp.up_proj.26      | 36003.320 |
+---------------------+-----------+
| mlp.up_proj.31      | 35895.352 |
+---------------------+-----------+
| mlp.gate_proj.23    | 34225.254 |
+---------------------+-----------+
| mlp.up_proj.25      | 33789.934 |
+---------------------+-----------+
| self_attn.k_proj.27 | 31995.322 |
+---------------------+-----------+
| self_attn.q_proj.27 | 31917.311 |
+---------------------+-----------+
| mlp.gate_proj.22    | 31869.490 |
+---------------------+-----------+
| self_attn.q_proj.28 | 31591.215 |
+---------------------+-----------+
| self_attn.k_proj.28 | 31446.244 |
+---------------------+-----------+
| mlp.up_proj.24      | 31336.875 |
+---------------------+-----------+
| self_attn.q_proj.25 | 30865.645 |
+---------------------+-----------+
| self_attn.k_proj.25 | 30664.000 |
+---------------------+-----------+
| self_attn.q_proj.30 | 30437.383 |
+---------------------+-----------+
| mlp.gate_proj.21    | 29812.947 |
+---------------------+-----------+
| self_attn.k_proj.30 | 29533.303 |
+---------------------+-----------+
| mlp.up_proj.23      | 29464.145 |
+---------------------+-----------+
| mlp.down_proj.31    | 29448.596 |
+---------------------+-----------+
| self_attn.q_proj.26 | 29209.996 |
+---------------------+-----------+
| self_attn.k_proj.26 | 29081.150 |
+---------------------+-----------+
| self_attn.q_proj.29 | 28527.668 |
+---------------------+-----------+


Optimizing mlp.gate_proj 30 ..
| mlp.gate_proj    | 20879.805    | 0.003      | 0.005     | 1.300 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 48027.406 |
+-------+-----------+-----------+
| 4     | 64        | 20879.805 |
+-------+-----------+-----------+


Optimizing mlp.gate_proj 29 ..
| mlp.gate_proj    | 20305.375    | 0.004      | 0.006     | 1.297 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 47030.266 |
+-------+-----------+-----------+
| 4     | 64        | 20305.375 |
+-------+-----------+-----------+


Optimizing mlp.gate_proj 28 ..
| mlp.gate_proj    | 19790.223    | 0.004      | 0.006     | 1.294 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 45704.352 |
+-------+-----------+-----------+
| 4     | 64        | 19790.223 |
+-------+-----------+-----------+


Optimizing mlp.gate_proj 27 ..
| mlp.gate_proj    | 19124.490    | 0.005      | 0.006     | 1.297 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 44196.207 |
+-------+-----------+-----------+
| 4     | 64        | 19124.490 |
+-------+-----------+-----------+


Optimizing mlp.up_proj 30 ..
| mlp.up_proj      | 18704.391    | 0.003      | 0.005     | 1.282 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 43075.492 |
+-------+-----------+-----------+
| 4     | 64        | 18704.391 |
+-------+-----------+-----------+


Optimizing mlp.up_proj 29 ..
| mlp.up_proj      | 18472.322    | 0.005      | 0.007     | 1.315 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 42815.773 |
+-------+-----------+-----------+
| 4     | 64        | 18472.322 |
+-------+-----------+-----------+


Optimizing mlp.gate_proj 26 ..
| mlp.gate_proj    | 18022.471    | 0.005      | 0.007     | 1.300 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 41528.125 |
+-------+-----------+-----------+
| 4     | 64        | 18022.471 |
+-------+-----------+-----------+


Optimizing mlp.up_proj 28 ..
| mlp.up_proj      | 17735.369    | 0.006      | 0.008     | 1.287 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 41086.469 |
+-------+-----------+-----------+
| 4     | 64        | 17735.369 |
+-------+-----------+-----------+


Optimizing mlp.gate_proj 31 ..
| mlp.gate_proj    | 17724.891    | 0.002      | 0.004     | 1.304 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 40273.055 |
+-------+-----------+-----------+
| 4     | 64        | 17724.891 |
+-------+-----------+-----------+


Optimizing mlp.gate_proj 25 ..
| mlp.gate_proj    | 16952.027    | 0.005      | 0.007     | 1.310 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 39067.656 |
+-------+-----------+-----------+
| 4     | 64        | 16952.027 |
+-------+-----------+-----------+


Optimizing mlp.up_proj 27 ..
| mlp.up_proj      | 16648        | 0.007      | 0.009     | 1.297 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 38600.137 |
+-------+-----------+-----------+
| 4     | 64        | 16648.000 |
+-------+-----------+-----------+


Optimizing mlp.gate_proj 24 ..
| mlp.gate_proj    | 15857.045    | 0.005      | 0.007     | 1.280 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 36352.875 |
+-------+-----------+-----------+
| 4     | 64        | 15857.045 |
+-------+-----------+-----------+


Optimizing mlp.up_proj 26 ..
| mlp.up_proj      | 15564.451    | 0.007      | 0.010     | 1.282 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 36003.320 |
+-------+-----------+-----------+
| 4     | 64        | 15564.451 |
+-------+-----------+-----------+


Optimizing mlp.up_proj 31 ..
| mlp.up_proj      | 15810.929    | 0.002      | 0.004     | 1.294 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 35895.352 |
+-------+-----------+-----------+
| 4     | 64        | 15810.929 |
+-------+-----------+-----------+


Optimizing mlp.gate_proj 23 ..
| mlp.gate_proj    | 14998.074    | 0.005      | 0.007     | 1.301 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 34225.254 |
+-------+-----------+-----------+
| 4     | 64        | 14998.074 |
+-------+-----------+-----------+


Optimizing mlp.up_proj 25 ..
| mlp.up_proj      | 14656.009    | 0.008      | 0.010     | 1.302 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 33789.934 |
+-------+-----------+-----------+
| 4     | 64        | 14656.009 |
+-------+-----------+-----------+


Optimizing self_attn.k_proj 27 ..
| self_attn.k_proj | 13639.273    | 0.002      | 0.003     | 1.278 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 31995.322 |
+-------+-----------+-----------+
| 4     | 64        | 13639.273 |
+-------+-----------+-----------+


Optimizing self_attn.q_proj 27 ..
| self_attn.q_proj | 13355.758    | 0.003      | 0.004     | 1.288 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 31917.311 |
+-------+-----------+-----------+
| 4     | 64        | 13355.758 |
+-------+-----------+-----------+


Optimizing mlp.gate_proj 22 ..
| mlp.gate_proj    | 14021.953    | 0.005      | 0.006     | 1.303 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 31869.490 |
+-------+-----------+-----------+
| 4     | 64        | 14021.953 |
+-------+-----------+-----------+


Optimizing self_attn.q_proj 28 ..
| self_attn.q_proj | 13066.777    | 0.003      | 0.004     | 1.329 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 31591.215 |
+-------+-----------+-----------+
| 4     | 64        | 13066.777 |
+-------+-----------+-----------+


Optimizing self_attn.k_proj 28 ..
| self_attn.k_proj | 13406.232    | 0.002      | 0.003     | 1.296 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 31446.244 |
+-------+-----------+-----------+
| 4     | 64        | 13406.232 |
+-------+-----------+-----------+


Optimizing mlp.up_proj 24 ..
| mlp.up_proj      | 13641.221    | 0.008      | 0.010     | 1.289 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 31336.875 |
+-------+-----------+-----------+
| 4     | 64        | 13641.221 |
+-------+-----------+-----------+


Optimizing self_attn.q_proj 25 ..
| self_attn.q_proj | 13049.916    | 0.003      | 0.004     | 1.276 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 30865.645 |
+-------+-----------+-----------+
| 4     | 64        | 13049.916 |
+-------+-----------+-----------+


Optimizing self_attn.k_proj 25 ..
| self_attn.k_proj | 13105.686    | 0.002      | 0.003     | 1.255 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 30664.000 |
+-------+-----------+-----------+
| 4     | 64        | 13105.686 |
+-------+-----------+-----------+


Optimizing self_attn.q_proj 30 ..
| self_attn.q_proj | 12192.358    | 0.003      | 0.003     | 1.303 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 30437.383 |
+-------+-----------+-----------+
| 4     | 64        | 12192.358 |
+-------+-----------+-----------+


Optimizing mlp.gate_proj 21 ..
| mlp.gate_proj    | 13152.599    | 0.005      | 0.006     | 1.307 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 29812.947 |
+-------+-----------+-----------+
| 4     | 64        | 13152.599 |
+-------+-----------+-----------+


Optimizing self_attn.k_proj 30 ..
| self_attn.k_proj | 12575.527    | 0.002      | 0.002     | 1.293 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 29533.303 |
+-------+-----------+-----------+
| 4     | 64        | 12575.527 |
+-------+-----------+-----------+


Optimizing mlp.up_proj 23 ..
| mlp.up_proj      | 12886.660    | 0.008      | 0.010     | 1.276 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 29464.145 |
+-------+-----------+-----------+
| 4     | 64        | 12886.660 |
+-------+-----------+-----------+


Optimizing mlp.down_proj 31 ..
| mlp.down_proj    | 13164.146    | 0.001      | 0.011     | 3.686 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 29448.596 |
+-------+-----------+-----------+
| 4     | 64        | 13164.146 |
+-------+-----------+-----------+


Optimizing self_attn.q_proj 26 ..
| self_attn.q_proj | 12131.626    | 0.003      | 0.004     | 1.311 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 29209.996 |
+-------+-----------+-----------+
| 4     | 64        | 12131.626 |
+-------+-----------+-----------+


Optimizing self_attn.k_proj 26 ..
| self_attn.k_proj | 12302.983    | 0.002      | 0.003     | 1.279 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 29081.150 |
+-------+-----------+-----------+
| 4     | 64        | 12302.983 |
+-------+-----------+-----------+


Optimizing self_attn.q_proj 29 ..
| self_attn.q_proj | 11463.815    | 0.003      | 0.004     | 1.287 |
+-------+-----------+-----------+
| wbits | groupsize |   error   |
+=======+===========+===========+
| 4     | 128       | 28527.668 |
+-------+-----------+-----------+
| 4     | 64        | 11463.815 |
+-------+-----------+-----------+


803.6325836181641
Downloading and preparing dataset wikitext/wikitext-2-raw-v1 to /home/v-wentaoni/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126...
Dataset wikitext downloaded and prepared to /home/v-wentaoni/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126. Subsequent calls will reuse this data.
wikitext2
Evaluating ...
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
5.6460041999816895
Downloading and preparing dataset ptb_text_only/penn_treebank to /home/v-wentaoni/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f...
Dataset ptb_text_only downloaded and prepared to /home/v-wentaoni/.cache/huggingface/datasets/ptb_text_only/penn_treebank/1.1.0/8d1b97746fb9765d140e569ec5ddd35e20af4d37761f5e1bf357ea0b081f2c1f. Subsequent calls will reuse this data.
ptb
Evaluating ...
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
85.71365356445312
c4
Evaluating ...
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
7.132997035980225
